{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4f163a2-4202-41a8-b75c-aaceb5f2accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io.arff import loadarff \n",
    "import time\n",
    "import scipy.spatial.distance as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57bc50c0-6056-49c6-a1d0-5d24053d9bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CARGAR LOS DATOS\n",
    "def load_df(data_name, ind):\n",
    "    train_set = pd.DataFrame()\n",
    "    test_set = pd.DataFrame()\n",
    "    i = ind\n",
    "    a = [1,2,3,4,5]\n",
    "    # print from ind-th index to (n+i)th index.\n",
    "    while i < 5 + (ind - 1):\n",
    "        txt = 'Instancias_APC/{d_name}_{n_data}.arff'\n",
    "        #print(txt.format(d_name = data_name, n_data = a[i % 5]))\n",
    "        raw_data = loadarff(txt.format(d_name = data_name, n_data = a[i % 5]))\n",
    "        raw_df_data = pd.DataFrame(raw_data[0])\n",
    "        train_set = pd.concat([train_set, raw_df_data], ignore_index=True)\n",
    "        i = i + 1\n",
    "        \n",
    "    \n",
    "    raw_data = loadarff(txt.format(d_name = data_name, n_data = ind))\n",
    "    raw_df_data = pd.DataFrame(raw_data[0])\n",
    "    test_set = pd.concat([test_set, raw_df_data], ignore_index=True)\n",
    "    \n",
    "    columns = train_set.columns[:-1] \n",
    "    for column in columns:\n",
    "        min_value = min(test_set[column].min(),train_set[column].min())\n",
    "        max_value = max(test_set[column].max(),train_set[column].max())\n",
    "        train_set[column] = (train_set[column] - min_value) / (max_value - min_value)\n",
    "        test_set[column] = (test_set[column] - min_value) / (max_value - min_value)\n",
    "    \n",
    "\n",
    "    if data_name == 'diabetes':\n",
    "        \n",
    "        values = train_set['class'].unique()\n",
    "        train_set.loc[train_set['class'] == values[0], 'class'] = 0\n",
    "        train_set.loc[train_set['class'] == values[1], 'class'] = 1\n",
    "        test_set.loc[test_set['class'] == values[0], 'class'] = 0\n",
    "        test_set.loc[test_set['class'] == values[1], 'class'] = 1\n",
    "        \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53644348-133c-4a47-99c3-d9d169f4a66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BUSQUEDA LOCAL\n",
    "def busqueda_local(X_train, y_train, w, f_value, max_iter):\n",
    "    iter_c = 0\n",
    "    iter_eval = 0\n",
    "    \n",
    "    columns_t = np.arange(len(X_train.columns))\n",
    "    \n",
    "    max_eval = 20 * len(X_train.columns)\n",
    "    \n",
    "    while iter_c < max_iter and iter_eval < max_eval:\n",
    "        \n",
    "        if len(columns_t) == 0:\n",
    "            columns_t = np.arange(len(X_train.columns))\n",
    "        \n",
    "        np.random.shuffle(columns_t)\n",
    "        s = np.random.normal(loc = 0, scale = 0.3)\n",
    "\n",
    "        w_new = w.copy()\n",
    "        w_new[columns_t[0]] += s\n",
    "        \n",
    "        w_new[w_new > 1] = 1\n",
    "        w_new[w_new < 0.1] = 0\n",
    "        \n",
    "        y_pred = validar_knn_train(X_train.copy(), y_train.copy(), w_new.copy())\n",
    "        class_v, red_v, f_value_new = func(y_train.copy(), y_pred.copy(), w_new.copy())\n",
    "        \n",
    "        if f_value_new > f_value:\n",
    "            w = w_new.copy()\n",
    "            f_value = f_value_new\n",
    "            iter_eval = 0\n",
    "        else:\n",
    "            iter_eval += 1\n",
    "        \n",
    "        columns_t = np.delete(columns_t, 0)\n",
    "        iter_c += 1\n",
    "        \n",
    "    return w, f_value, iter_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa7fc856",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "## GREEDY\n",
    "def lookForEnemy(X_train, y_train, e_index):\n",
    "    e_class = y_train[e_index]\n",
    "    enemy = X_train.loc[y_train[y_train != e_class].index, :]\n",
    "    A = enemy.copy()\n",
    "    A = (A - X_train.iloc[e_index])**2\n",
    "    A['d'] = 0\n",
    "    A['d'] = np.sqrt(A.sum(axis = 1).values)\n",
    "    index = A[A['d'] == A['d'].min()].index[0]                        \n",
    "    return index\n",
    "\n",
    "def lookForFriend(X_train, y_train, e_index):\n",
    "    e_class = y_train[e_index]\n",
    "    friend = X_train.loc[y_train[y_train == e_class].index, :]\n",
    "    A = friend.copy()\n",
    "    A = (A - X_train.iloc[e_index])**2\n",
    "    A['d'] = 0\n",
    "    A['d'] = np.sqrt(A.sum(axis = 1).values)\n",
    "    index = A[A['d'] == (A[A['d'] != 0.0]['d'].min())].index[0]\n",
    "    return index\n",
    "            \n",
    "        \n",
    "def greedy(X_train, y_train):\n",
    "    w = np.zeros(X_train.shape[1])\n",
    "    for i in range(X_train.shape[0]):\n",
    "        ec_index = lookForEnemy(X_train, y_train, i)\n",
    "        ac_index = lookForFriend(X_train, y_train, i)\n",
    "        w = w + abs(X_train.iloc[i].values - X_train.loc[ec_index].values) - abs(X_train.iloc[i].values - X_train.loc[ac_index].values)\n",
    "\n",
    "    w_max = max(w)\n",
    "    w[w>=0.1] = w[w>=0.1]/w_max\n",
    "    w[w<0.1] = 0\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a707e67-a6ac-4f6d-a2c7-588e503e1d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## VALIDACION\n",
    "\n",
    "def validar_knn(X_train, y_train, x_test, w_true):\n",
    "    w = w_true.copy()\n",
    "    w[w<0.1] = 0\n",
    "    w[w > 1] = 1\n",
    "    X_train_p = pd.concat([X_train, x_test], ignore_index=True)\n",
    "    dm = dt.pdist(X_train_p, metric = \"euclidean\", w = w)\n",
    "    a = pd.DataFrame(dt.squareform(dm)) \n",
    "    indexes = a.loc[X_train.shape[0]:, :X_train.shape[0] - 1].idxmin(axis=1)\n",
    "    y_pred = y_train[indexes].values\n",
    "    return y_pred\n",
    "\n",
    "def validar_knn_train(X_train, y_train, w_true):\n",
    "    w = w_true.copy()\n",
    "    y_pred = np.zeros(len(y_train))\n",
    "    w[w < 0.1] = 0\n",
    "    w[w > 1] = 1\n",
    "    dm = dt.pdist(X_train, metric = \"euclidean\", w = w)\n",
    "    a = pd.DataFrame(dt.squareform(dm))\n",
    "    np.fill_diagonal(a.values, 99999)\n",
    "    indexes = a.idxmin(axis = 1)\n",
    "    y_pred = y_train[indexes].values \n",
    "    return y_pred\n",
    "    \n",
    "def func(y_true, y_pred, w_true):\n",
    "    w = w_true.copy()\n",
    "    w[w < 0] = 0\n",
    "    w[w > 1] = 1\n",
    "    arr_p = np.where((y_true-y_pred) == 0)\n",
    "    aciertos = len(arr_p[0])\n",
    "    \n",
    "    tasa_class = 100.0*(aciertos/len(y_true))\n",
    "    tasa_red = 100.0*(len(w[w<0.1])/len(w))\n",
    "\n",
    "    return tasa_class, tasa_red, 0.8*tasa_class + 0.2*tasa_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29865098-9fa6-4e98-98e6-a8078355c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def operar_cruces(tipo_cruce , next_gen, n_esperado_cruces):\n",
    "    #Cruce BLX\n",
    "    if tipo_cruce == 1:\n",
    "        alpha = 0.3\n",
    "        iterator = 0\n",
    "        while iterator < n_esperado_cruces:\n",
    "            for j in range(len(next_gen[iterator])):\n",
    "                cmax = max(next_gen[iterator][j], next_gen[iterator+1][j])\n",
    "                cmin = min(next_gen[iterator][j], next_gen[iterator+1][j])\n",
    "                i_cru = cmax - cmin\n",
    "                next_gen[iterator][j] = np.random.uniform(cmin - i_cru * alpha, cmax + i_cru * alpha)\n",
    "                next_gen[iterator + 1][j] = np.random.uniform(cmin - i_cru * alpha, cmax + i_cru * alpha)\n",
    "            \n",
    "                if next_gen[iterator][j] > 1:\n",
    "                    next_gen[iterator][j] = 1\n",
    "                if next_gen[iterator][j] < 0.1:\n",
    "                    next_gen[iterator][j] = 0\n",
    "                    \n",
    "                if next_gen[iterator+1][j] > 1:\n",
    "                    next_gen[iterator+1][j] = 1\n",
    "                if next_gen[iterator+1][j] < 0.1:\n",
    "                    next_gen[iterator+1][j] = 0\n",
    "                    \n",
    "            iterator = iterator + 2\n",
    "    #CRUCE ARITMETICO\n",
    "    elif tipo_cruce == 2:\n",
    "        #Cruce aritmetico\n",
    "        iterator = 0\n",
    "        while iterator < n_esperado_cruces:\n",
    "            alpha = np.random.uniform(0, 1)\n",
    "            a = alpha * next_gen[iterator] + (1-alpha) * next_gen[iterator + 1]\n",
    "            b = alpha * next_gen[iterator+1] + (1-alpha) * next_gen[iterator]\n",
    "            \n",
    "            next_gen[iterator] = a\n",
    "            next_gen[iterator+1] = b\n",
    "            \n",
    "            next_gen[iterator][next_gen[iterator] > 1] = 1\n",
    "            next_gen[iterator][next_gen[iterator] < 0.1] = 0\n",
    "            \n",
    "            next_gen[iterator+1][next_gen[iterator+1] > 1] = 1\n",
    "            next_gen[iterator+1][next_gen[iterator+1] < 0.1] = 0\n",
    "            \n",
    "            iterator = iterator + 2\n",
    "    \n",
    "    return next_gen\n",
    "\n",
    "def agg(X_train, y_train, tipo_cruce):\n",
    "    ws = []\n",
    "    ws_fitness = []\n",
    "    vecinos = 50\n",
    "    iter_ = 0\n",
    "    max_iters = 15000\n",
    "    #Generamos los primeros 50 cromosomas\n",
    "    for i in range(vecinos):\n",
    "        w = np.random.uniform(0, 1, X_train.shape[1])\n",
    "        y_pred = validar_knn_train(X_train.copy(), y_train.copy(), np.array(w))\n",
    "        class_v, red_v, f_value = func(y_train.copy(), y_pred.copy(), np.array(w))    \n",
    "        ws.append(w)\n",
    "        ws_fitness.append(f_value)\n",
    "        \n",
    "    while iter_ < max_iters:\n",
    "        \n",
    "        next_gen = []\n",
    "        next_gen_fitness = []\n",
    "           \n",
    "        # Escogemos los padres\n",
    "        for i in range(vecinos):\n",
    "            i_1 = np.random.randint(0, len(ws)-1)\n",
    "            i_2 = np.random.randint(0, len(ws)-1)\n",
    "\n",
    "            if ws_fitness[i_1] > ws_fitness[i_2]:\n",
    "                next_gen.append(ws[i_1])\n",
    "            else:\n",
    "                next_gen.append(ws[i_2])\n",
    "  \n",
    "\n",
    "        #Cruzamos los padres\n",
    "        new_next_gen = operar_cruces(tipo_cruce, next_gen.copy(), int(0.7 * vecinos))\n",
    "\n",
    "        #Mutamos\n",
    "        numero_mutados = int(len(new_next_gen) * 0.1)\n",
    "        for i in range(numero_mutados):\n",
    "            i_1 = np.random.randint(0, len(new_next_gen)-1)\n",
    "            \n",
    "            columns_t = np.arange(len(X_train.columns))\n",
    "        \n",
    "            np.random.shuffle(columns_t)\n",
    "            s = np.random.normal(0, 0.3)\n",
    "\n",
    "            new_next_gen[i_1][columns_t[0]] += s\n",
    "      \n",
    "            new_next_gen[i_1][new_next_gen[i_1] > 1] = 1\n",
    "            new_next_gen[i_1][new_next_gen[i_1] < 0.1] = 0\n",
    "            \n",
    "                \n",
    "\n",
    "        # AQUI REEVALUAMOS LA NUEVA POBLACION\n",
    "        # ITERACIONES += 50\n",
    "        for i in range(vecinos):\n",
    "            y_pred = validar_knn_train(X_train.copy(), y_train.copy(), np.array(new_next_gen[i]))\n",
    "            class_v, red_v, f_value = func(y_train.copy(), y_pred.copy(), np.array(new_next_gen[i]))    \n",
    "            next_gen_fitness.append(f_value)\n",
    "            \n",
    "        iter_ += 50\n",
    "        \n",
    "        #Si la mejor solucion de la familia anterior no esta en la siguiente generacion\n",
    "        #sustituimos la peor de la actual generacion por la mejor de la anterior\n",
    "      \n",
    "        idx_worst = np.where(next_gen_fitness == np.min(next_gen_fitness))[0][0]\n",
    "        idx_best = np.where(ws_fitness == np.max(ws_fitness))[0][0]\n",
    "  \n",
    "        if abs((new_next_gen[idx_worst] - ws[idx_best]).sum()) > 0:\n",
    "            new_next_gen[idx_worst] = ws[idx_best]\n",
    "            next_gen_fitness[idx_worst] = ws_fitness[idx_best]\n",
    "           \n",
    "        ws = new_next_gen.copy()\n",
    "        ws_fitness = next_gen_fitness.copy()\n",
    "    \n",
    "    idx_best = np.where(ws_fitness == np.max(ws_fitness))[0][0]\n",
    "\n",
    "    return ws[idx_best]\n",
    "\n",
    "\n",
    "\n",
    "def age(X_train, y_train, tipo_cruce):\n",
    "    ws = []\n",
    "    ws_fitness = []\n",
    "    vecinos = 50\n",
    "    iter_ = 0\n",
    "    max_iters = 15000\n",
    "    \n",
    "    #Generamos los primeros 50 cromosomas\n",
    "    for i in range(vecinos):\n",
    "        w = np.random.uniform(0, 1, X_train.shape[1])\n",
    "        y_pred = validar_knn_train(X_train.copy(), y_train.copy(), np.array(w))\n",
    "        class_v, red_v, f_value = func(y_train.copy(), y_pred, np.array(w))    \n",
    "        ws.append(w)\n",
    "        ws_fitness.append(f_value)\n",
    "\n",
    "    while iter_ < max_iters:\n",
    "        \n",
    "        next_gen = []\n",
    "        dict_arr = {}\n",
    "        \n",
    "        for i in range(2):\n",
    "            i_1 = np.random.randint(0, len(ws)-1)\n",
    "            i_2 = np.random.randint(0, len(ws)-1)\n",
    "\n",
    "            if ws_fitness[i_1] > ws_fitness[i_2]:\n",
    "                next_gen.append(ws[i_1])\n",
    "            else:\n",
    "                next_gen.append(ws[i_2])\n",
    "                \n",
    "\n",
    "        #Cruzamos los padres\n",
    "        next_gen = operar_cruces(tipo_cruce, next_gen.copy(), len(next_gen))\n",
    "        \n",
    "        s = np.random.normal(0, 0.3)\n",
    "        #Mutamos\n",
    "        for i in range(len(next_gen)):\n",
    "            probability = np.random.uniform(0, 1)\n",
    "\n",
    "            if probability <= 0.1:\n",
    "                columns_t = np.arange(len(X_train.columns))\n",
    "\n",
    "                np.random.shuffle(columns_t)\n",
    "                s = np.random.normal(0, 0.3)\n",
    "\n",
    "                next_gen[i][columns_t[0]] += s\n",
    "                    \n",
    "                next_gen[i][next_gen[i] > 1] = 1\n",
    "                next_gen[i][next_gen[i] < 0.1] = 0\n",
    "                \n",
    "        #Evaluamos los dos nuevos cromosomas\n",
    "        for i in range(2):\n",
    "            y_pred = validar_knn_train(X_train.copy(), y_train.copy(), np.array(next_gen[i]))\n",
    "            class_v, red_v, f_value = func(y_train.copy(), y_pred, np.array(next_gen[i]))    \n",
    "            dict_arr[vecinos + i] = f_value\n",
    "            ws.append(next_gen[i])\n",
    "            ws_fitness.append(f_value)\n",
    "                                                                                                              \n",
    "        iter_ += 2\n",
    "        \n",
    "        #Nos \n",
    "        idx_worst, idx_worst_2 = np.argpartition(ws_fitness, 1)[0:2] \n",
    "        dict_arr[idx_worst] = ws_fitness[idx_worst]\n",
    "        dict_arr[idx_worst_2] = ws_fitness[idx_worst_2]           \n",
    "        dict_arr = dict(sorted(dict_arr.items(), key=lambda item: item[1], reverse=True)) \n",
    "        keysList = list(dict_arr.keys())\n",
    "        for counter, index in enumerate(keysList[-2:]):\n",
    "            ws.pop(index - counter)\n",
    "            ws_fitness.pop(index-counter)\n",
    "                \n",
    "\n",
    "    idx_best = np.where(ws_fitness == np.max(ws_fitness))[0][0]\n",
    "\n",
    "    return ws[idx_best]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ad23ac4-edea-42c4-8a2a-c1a01bed24a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memetico(X_train, y_train, tipo_memetico):\n",
    "    ws = []\n",
    "    ws_fitness = []\n",
    "    vecinos = 50\n",
    "    iter_ = 0\n",
    "    max_iters = 15000\n",
    "    generacion = 0\n",
    "    #Generamos los primeros 50 cromosomas\n",
    "    for i in range(vecinos):\n",
    "        w = np.random.uniform(0, 1, X_train.shape[1])\n",
    "        y_pred = validar_knn_train(X_train.copy(), y_train.copy(), np.array(w))\n",
    "        class_v, red_v, f_value = func(y_train.copy(), y_pred.copy(), np.array(w))    \n",
    "        ws.append(w)\n",
    "        ws_fitness.append(f_value)\n",
    "        \n",
    "    while iter_ < max_iters:\n",
    "        \n",
    "        next_gen = []\n",
    "        next_gen_fitness = []\n",
    "           \n",
    "        # Escogemos los padres\n",
    "        for i in range(vecinos):\n",
    "            i_1 = np.random.randint(0, len(ws)-1)\n",
    "            i_2 = np.random.randint(0, len(ws)-1)\n",
    "\n",
    "            if ws_fitness[i_1] > ws_fitness[i_2]:\n",
    "                next_gen.append(ws[i_1])\n",
    "            else:\n",
    "                next_gen.append(ws[i_2])\n",
    "  \n",
    "\n",
    "        #Cruzamos los padres\n",
    "        #Cruce blx\n",
    "        new_next_gen = operar_cruces(1, next_gen.copy(), int(0.7 * vecinos))\n",
    "\n",
    "        #Mutamos\n",
    "        numero_mutados = int(len(new_next_gen) * 0.1)\n",
    "        for i in range(numero_mutados):\n",
    "            i_1 = np.random.randint(0, len(new_next_gen)-1)\n",
    "            \n",
    "            columns_t = np.arange(len(X_train.columns))\n",
    "        \n",
    "            np.random.shuffle(columns_t)\n",
    "            s = np.random.normal(0, 0.3)\n",
    "\n",
    "            new_next_gen[i_1][columns_t[0]] += s\n",
    "\n",
    "            next_gen[i_1][next_gen[i_1] > 1] = 1\n",
    "            next_gen[i_1][next_gen[i_1] < 0.1] = 0\n",
    "                \n",
    "\n",
    "        for i in range(vecinos):\n",
    "            y_pred = validar_knn_train(X_train.copy(), y_train.copy(), np.array(new_next_gen[i]))\n",
    "            class_v, red_v, f_value = func(y_train.copy(), y_pred.copy(), np.array(new_next_gen[i]))    \n",
    "            next_gen_fitness.append(f_value) \n",
    "        \n",
    "        iter_ += 50\n",
    "\n",
    "\n",
    "        generacion += 1\n",
    "\n",
    "        if generacion%10 == 0:\n",
    "            if tipo_memetico == 1:\n",
    "                \n",
    "                for i in range(vecinos):\n",
    "                    new_w, f_value, iteraciones_realizadas =  busqueda_local(X_train.copy(), y_train.copy(), new_next_gen[i].copy(), next_gen_fitness[i], 400)\n",
    "                    new_next_gen[i] = new_w\n",
    "                    next_gen_fitness[i] = f_value\n",
    "                    iter_ += iteraciones_realizadas\n",
    "                \n",
    "            elif tipo_memetico == 2:\n",
    "                num_index = np.arange(vecinos)\n",
    "                np.random.shuffle(num_index)      \n",
    "                for i in range(5):\n",
    "                    new_w, f_value, iteraciones_realizadas =  busqueda_local(X_train.copy(), y_train.copy(), new_next_gen[num_index[i]].copy(), next_gen_fitness[num_index[i]], 400)\n",
    "                    new_next_gen[num_index[i]] = new_w\n",
    "                    next_gen_fitness[num_index[i]] = f_value \n",
    "                    iter_ += iteraciones_realizadas\n",
    "\n",
    "            elif tipo_memetico == 3:\n",
    "                index_best = np.argpartition(next_gen_fitness, -5)[-5:]\n",
    "                for i in range(5):\n",
    "                    new_w, f_value, iteraciones_realizadas =  busqueda_local(X_train.copy(), y_train.copy(), new_next_gen[index_best[i]].copy(), next_gen_fitness[index_best[i]], 400)\n",
    "                    new_next_gen[index_best[i]] = new_w\n",
    "                    next_gen_fitness[index_best[i]] = f_value\n",
    "                    iter_ += iteraciones_realizadas\n",
    "        \n",
    "        #Si la mejor solucion de la familia anterior no esta en la siguiente generacion\n",
    "        #sustituimos la peor de la actual generacion por la mejor de la anterior\n",
    "      \n",
    "        idx_worst = np.where(next_gen_fitness == np.min(next_gen_fitness))[0][0]\n",
    "        idx_best = np.where(ws_fitness == np.max(ws_fitness))[0][0]\n",
    "  \n",
    "        if abs((new_next_gen[idx_worst] - ws[idx_best]).sum()) > 0:\n",
    "            new_next_gen[idx_worst] = ws[idx_best]\n",
    "            next_gen_fitness[idx_worst] = ws_fitness[idx_best]\n",
    "           \n",
    "        ws = new_next_gen.copy()\n",
    "        ws_fitness = next_gen_fitness.copy()\n",
    "            \n",
    "    idx_best = np.where(ws_fitness == np.max(ws_fitness))[0][0]\n",
    "\n",
    "    return ws[idx_best]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8d01660-0a10-4c57-9f18-4de17331def4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** Exp : diabetes **************\n",
      "Partition %_class %_red Fit T\n",
      "1 , 67.53246753246754 , 37.5 , 61.52597402597403 , 130.99239325523376\n",
      "2 , 66.23376623376623 , 62.5 , 65.48701298701299 , 133.74494791030884\n",
      "3 , 61.68831168831169 , 87.5 , 66.85064935064935 , 140.19406080245972\n",
      "4 , 64.28571428571429 , 75.0 , 66.42857142857144 , 123.23821973800659\n",
      "5 , 72.36842105263158 , 75.0 , 72.89473684210526 , 144.5779848098755\n",
      "Media %class 66.42173615857827\n",
      "Media %red 67.5\n",
      "Media fitness 66.63738892686261\n",
      "Media tiempo 134.54952130317687\n",
      "******** Exp : ozone-320 **************\n",
      "Partition %_class %_red Fit T\n",
      "1 , 81.25 , 38.88888888888889 , 72.77777777777777 , 74.79161882400513\n",
      "2 , 76.5625 , 37.5 , 68.75 , 78.18833827972412\n",
      "3 , 82.8125 , 44.44444444444444 , 75.13888888888889 , 78.00123167037964\n",
      "4 , 75.0 , 44.44444444444444 , 68.88888888888889 , 74.69837021827698\n",
      "5 , 79.6875 , 40.27777777777778 , 71.80555555555556 , 77.41282391548157\n",
      "Media %class 79.0625\n",
      "Media %red 41.11111111111111\n",
      "Media fitness 71.47222222222221\n",
      "Media tiempo 76.61847658157349\n",
      "******** Exp : spectf-heart **************\n",
      "Partition %_class %_red Fit T\n",
      "1 , 77.14285714285715 , 68.18181818181817 , 75.35064935064936 , 56.7277410030365\n",
      "2 , 84.28571428571429 , 54.54545454545454 , 78.33766233766234 , 53.19824457168579\n",
      "3 , 92.85714285714286 , 50.0 , 84.28571428571429 , 42.118051290512085\n",
      "4 , 82.85714285714286 , 72.72727272727273 , 80.83116883116884 , 39.754881620407104\n",
      "5 , 78.26086956521739 , 52.27272727272727 , 73.06324110671937 , 38.14932417869568\n",
      "Media %class 83.08074534161491\n",
      "Media %red 59.54545454545454\n",
      "Media fitness 78.37368718238284\n",
      "Media tiempo 45.989648532867434\n"
     ]
    }
   ],
   "source": [
    "# NOMBRE DE LOS DATASETS\n",
    "datasets_names = ['diabetes', 'ozone-320', 'spectf-heart']\n",
    "\n",
    "# SEMILLA\n",
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "\n",
    "#Names: BL(BUSQUEDA LOCAL), AGG-BLX, AGG-CA, AGE-BLX, AGE-CA, AM-ALL, AM-RAND, AM-BEST, greedy, knn\n",
    "alg = \"AM-BEST\"\n",
    "\n",
    "for name in datasets_names:\n",
    "    print(\"******** Exp :\", name, \"**************\")\n",
    "    print(\"Partition\", \"%_class\", \"%_red\", \"Fit\", \"T\")\n",
    "    mean_t = []\n",
    "    mean_fit = []\n",
    "    mean_class = []\n",
    "    mean_red = []\n",
    "    \n",
    "    for i in range(5):   \n",
    "\n",
    "        train = pd.DataFrame()\n",
    "        test = pd.DataFrame()\n",
    "        data_name = name\n",
    "        train, test = load_df(data_name, i+1)\n",
    "\n",
    "        X_train = train\n",
    "        if name == 'diabetes':\n",
    "            y_train = train['class'].astype(int)\n",
    "            X_train = X_train.drop(columns = ['class'])\n",
    "        else:\n",
    "            y_train = train['Class'].astype(int)\n",
    "            X_train = X_train.drop(columns = ['Class'])\n",
    "\n",
    "        x_test = test\n",
    "        if name == 'diabetes':\n",
    "            y_test = test['class'].astype(int)\n",
    "            x_test = x_test.drop(columns = ['class'])\n",
    "        else:\n",
    "            y_test = test['Class'].astype(int)\n",
    "            x_test = x_test.drop(columns = ['Class'])\n",
    "\n",
    "\n",
    "        inicio = time.time()\n",
    "        if alg == \"BL\":\n",
    "            w_bl, a, b = busqueda_local(X_train.copy(), y_train.copy(), np.random.uniform(0, 1, X_train.shape[1]), 0.0, 15000)\n",
    "        elif alg == \"AGG-BLX\":\n",
    "            w_bl = agg(X_train.copy(), y_train.copy(), tipo_cruce = 1)\n",
    "        elif alg == \"AGG-CA\":\n",
    "            w_bl = agg(X_train.copy(), y_train.copy(), tipo_cruce = 2)\n",
    "        elif alg == \"AGE-BLX\":\n",
    "            w_bl = age(X_train.copy(), y_train.copy(), tipo_cruce = 1)\n",
    "        elif alg == \"AGE-CA\":\n",
    "            w_bl = age(X_train.copy(), y_train.copy(), tipo_cruce = 2)\n",
    "        elif alg == \"AM-ALL\":\n",
    "            w_bl = memetico(X_train, y_train, 1)\n",
    "        elif alg == \"AM-RAND\":\n",
    "            w_bl = memetico(X_train, y_train, 2)\n",
    "        elif alg == \"AM-BEST\":\n",
    "            w_bl = memetico(X_train, y_train, 3)\n",
    "        elif alg == 'knn':\n",
    "            w_bl = np.ones(X_train.shape[1])\n",
    "        elif alg == 'greedy':\n",
    "            w_bl = greedy(X_train.copy(), y_train.copy())\n",
    "       \n",
    "        fin = time.time()\n",
    "        tiempo = (fin-inicio)\n",
    "\n",
    "        y_pred = validar_knn(X_train.copy(), y_train.copy(), x_test.copy(), w_bl)\n",
    "        class_v, red_v, f_value = func(y_test.copy(), y_pred.copy(), w_bl)\n",
    "\n",
    "        print(i + 1, \",\", class_v , \",\" , red_v, \",\", f_value, \",\", tiempo)\n",
    "        mean_fit.append(f_value)\n",
    "        mean_t.append(tiempo)\n",
    "        mean_class.append(class_v)\n",
    "        mean_red.append(red_v)\n",
    "\n",
    "    print(\"Media %class\", np.array(mean_class).mean())\n",
    "    print(\"Media %red\", np.array(mean_red).mean())\n",
    "    print(\"Media fitness\", np.array(mean_fit).mean())\n",
    "    print(\"Media tiempo\", np.array(mean_t).mean())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ab8c11-5f05-4ea6-8460-d06bc81002e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
