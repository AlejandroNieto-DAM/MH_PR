{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4f163a2-4202-41a8-b75c-aaceb5f2accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io.arff import loadarff \n",
    "import time\n",
    "import scipy.spatial.distance as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57bc50c0-6056-49c6-a1d0-5d24053d9bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CARGAR LOS DATOS\n",
    "def load_df(data_name, ind):\n",
    "    train_set = pd.DataFrame()\n",
    "    test_set = pd.DataFrame()\n",
    "    i = ind\n",
    "    a = [1,2,3,4,5]\n",
    "    # print from ind-th index to (n+i)th index.\n",
    "    while i < 5 + (ind - 1):\n",
    "        txt = 'Instancias_APC/{d_name}_{n_data}.arff'\n",
    "        #print(txt.format(d_name = data_name, n_data = a[i % 5]))\n",
    "        raw_data = loadarff(txt.format(d_name = data_name, n_data = a[i % 5]))\n",
    "        raw_df_data = pd.DataFrame(raw_data[0])\n",
    "        train_set = pd.concat([train_set, raw_df_data], ignore_index=True)\n",
    "        i = i + 1\n",
    "        \n",
    "    \n",
    "    raw_data = loadarff(txt.format(d_name = data_name, n_data = ind))\n",
    "    raw_df_data = pd.DataFrame(raw_data[0])\n",
    "    test_set = pd.concat([test_set, raw_df_data], ignore_index=True)\n",
    "    \n",
    "    columns = train_set.columns[:-1] \n",
    "    for column in columns:\n",
    "        min_value = min(test_set[column].min(),train_set[column].min())\n",
    "        max_value = max(test_set[column].max(),train_set[column].max())\n",
    "        train_set[column] = (train_set[column] - min_value) / (max_value - min_value)\n",
    "        test_set[column] = (test_set[column] - min_value) / (max_value - min_value)\n",
    "    \n",
    "\n",
    "    if data_name == 'diabetes':\n",
    "        \n",
    "        values = train_set['class'].unique()\n",
    "        train_set.loc[train_set['class'] == values[0], 'class'] = 0\n",
    "        train_set.loc[train_set['class'] == values[1], 'class'] = 1\n",
    "        test_set.loc[test_set['class'] == values[0], 'class'] = 0\n",
    "        test_set.loc[test_set['class'] == values[1], 'class'] = 1\n",
    "        \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50085578-a62d-446d-a566-57d32c0a2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GREEDY\n",
    "def lookForEnemy(X_train, y_train, e_index):\n",
    "    e_class = y_train[e_index]\n",
    "    enemy = X_train.loc[y_train[y_train != e_class].index, :]\n",
    "    A = enemy.copy()\n",
    "    A = (A - X_train.iloc[e_index])**2\n",
    "    A['d'] = 0\n",
    "    A['d'] = np.sqrt(A.sum(axis = 1).values)\n",
    "    index = A[A['d'] == A['d'].min()].index[0]                        \n",
    "    return index\n",
    "\n",
    "def lookForFriend(X_train, y_train, e_index):\n",
    "    e_class = y_train[e_index]\n",
    "    friend = X_train.loc[y_train[y_train == e_class].index, :]\n",
    "    A = friend.copy()\n",
    "    A = (A - X_train.iloc[e_index])**2\n",
    "    A['d'] = 0\n",
    "    A['d'] = np.sqrt(A.sum(axis = 1).values)\n",
    "    index = A[A['d'] == (A[A['d'] != 0.0]['d'].min())].index[0]\n",
    "    return index\n",
    "            \n",
    "        \n",
    "def greedy(X_train, y_train):\n",
    "    w = np.zeros(X_train.shape[1])\n",
    "    for i in range(X_train.shape[0]):\n",
    "        ec_index = lookForEnemy(X_train, y_train, i)\n",
    "        ac_index = lookForFriend(X_train, y_train, i)\n",
    "        w = w + abs(X_train.iloc[i].values - X_train.loc[ec_index].values) - abs(X_train.iloc[i].values - X_train.loc[ac_index].values)\n",
    "\n",
    "    w_max = max(w)\n",
    "    w[w>=0.1] = w[w>=0.1]/w_max\n",
    "    w[w<0.1] = 0\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53644348-133c-4a47-99c3-d9d169f4a66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BUSQUEDA LOCAL\n",
    "def busqueda_local(X_train, y_train, w, f_value, max_iter):\n",
    "    iter_c = 0\n",
    "    iter_eval = 0\n",
    "    \n",
    "    columns_t = np.arange(len(X_train.columns))\n",
    "    \n",
    "    max_eval = 20 * len(X_train.columns)\n",
    "    \n",
    "    while iter_c < max_iter and iter_eval < max_eval:\n",
    "        \n",
    "        if len(columns_t) == 0:\n",
    "            columns_t = np.arange(len(X_train.columns))\n",
    "        \n",
    "        np.random.shuffle(columns_t)\n",
    "        s = np.random.normal(loc = 0, scale = 0.3)\n",
    "\n",
    "        w_new = w.copy()\n",
    "        w_new[columns_t[0]] += s\n",
    "        \n",
    "        w_new[w_new > 1] = 1\n",
    "        w_new[w_new < 0.1] = 0\n",
    "        \n",
    "        y_pred = validar_knn_train(X_train.copy(), y_train.copy(), w_new.copy())\n",
    "        class_v, red_v, f_value_new = func(y_train.copy(), y_pred.copy(), w_new.copy())\n",
    "        \n",
    "        if f_value_new > f_value:\n",
    "            w = w_new.copy()\n",
    "            f_value = f_value_new\n",
    "            iter_eval = 0\n",
    "        else:\n",
    "            iter_eval += 1\n",
    "        \n",
    "        columns_t = np.delete(columns_t, 0)\n",
    "        iter_c += 1\n",
    "        \n",
    "    return w, f_value, iter_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a707e67-a6ac-4f6d-a2c7-588e503e1d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## VALIDACION\n",
    "\n",
    "def validar_knn(X_train, y_train, x_test, w_true):\n",
    "    w = w_true.copy()\n",
    "    w[w<0.1] = 0\n",
    "    w[w > 1] = 1\n",
    "    X_train_p = pd.concat([X_train, x_test], ignore_index=True)\n",
    "    dm = dt.pdist(X_train_p, metric = \"euclidean\", w = w)\n",
    "    a = pd.DataFrame(dt.squareform(dm)) \n",
    "    indexes = a.loc[X_train.shape[0]:, :X_train.shape[0] - 1].idxmin(axis=1)\n",
    "    y_pred = y_train[indexes].values\n",
    "    return y_pred\n",
    "\n",
    "def validar_knn_train(X_train, y_train, w_true):\n",
    "    w = w_true.copy()\n",
    "    y_pred = np.zeros(len(y_train))\n",
    "    w[w < 0.1] = 0\n",
    "    w[w > 1] = 1\n",
    "    dm = dt.pdist(X_train, metric = \"euclidean\", w = w)\n",
    "    a = pd.DataFrame(dt.squareform(dm))\n",
    "    np.fill_diagonal(a.values, 99999)\n",
    "    indexes = a.idxmin(axis = 1)\n",
    "    y_pred = y_train[indexes].values \n",
    "    return y_pred\n",
    "    \n",
    "def func(y_true, y_pred, w_true):\n",
    "    w = w_true.copy()\n",
    "    w[w < 0] = 0\n",
    "    w[w > 1] = 1\n",
    "    arr_p = np.where((y_true-y_pred) == 0)\n",
    "    aciertos = len(arr_p[0])\n",
    "    \n",
    "    tasa_class = 100.0*(aciertos/len(y_true))\n",
    "    tasa_red = 100.0*(len(w[w<0.1])/len(w))\n",
    "\n",
    "    return tasa_class, tasa_red, 0.8*tasa_class + 0.2*tasa_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24fe61b9-8c9f-47f6-af7b-57ca9542da3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** Exp : diabetes **************\n",
      "Partition %_class %_red Fit T\n",
      "1 , 66.88311688311688 , 0.0 , 53.50649350649351 , 0.005523681640625\n",
      "2 , 66.88311688311688 , 0.0 , 53.50649350649351 , 0.02256035804748535\n",
      "3 , 68.83116883116884 , 0.0 , 55.06493506493507 , 0.0\n",
      "4 , 69.48051948051948 , 0.0 , 55.58441558441558 , 0.008001089096069336\n",
      "5 , 69.73684210526315 , 0.0 , 55.78947368421052 , 0.0019998550415039062\n",
      "Media %class 68.36295283663705\n",
      "Media %red 0.0\n",
      "Media fitness 54.69036226930964\n",
      "Media tiempo 0.007616996765136719\n",
      "******** Exp : ozone-320 **************\n",
      "Partition %_class %_red Fit T\n",
      "1 , 78.125 , 0.0 , 62.5 , 0.0\n",
      "2 , 85.9375 , 0.0 , 68.75 , 0.0\n",
      "3 , 79.6875 , 0.0 , 63.75 , 0.005000114440917969\n",
      "4 , 76.5625 , 0.0 , 61.25 , 0.0\n",
      "5 , 81.25 , 0.0 , 65.0 , 0.016118526458740234\n",
      "Media %class 80.3125\n",
      "Media %red 0.0\n",
      "Media fitness 64.25\n",
      "Media tiempo 0.00422372817993164\n",
      "******** Exp : spectf-heart **************\n",
      "Partition %_class %_red Fit T\n",
      "1 , 77.14285714285715 , 0.0 , 61.71428571428572 , 0.008322715759277344\n",
      "2 , 88.57142857142857 , 0.0 , 70.85714285714286 , 0.0033769607543945312\n",
      "3 , 91.42857142857143 , 0.0 , 73.14285714285715 , 0.0\n",
      "4 , 85.71428571428571 , 0.0 , 68.57142857142857 , 0.0\n",
      "5 , 84.05797101449275 , 0.0 , 67.2463768115942 , 0.015644073486328125\n",
      "Media %class 85.38302277432713\n",
      "Media %red 0.0\n",
      "Media fitness 68.30641821946169\n",
      "Media tiempo 0.00546875\n"
     ]
    }
   ],
   "source": [
    "## CUERPO DEL PROGRAMA\n",
    "datasets_names = ['diabetes', 'ozone-320', 'spectf-heart']\n",
    "\n",
    "# Cambiamos esta variable para seleccionar el tipo de algoritmo que vamos a usar\n",
    "using = 'knn' #Values 'greedy' 'busqueda_local' 'knn' \n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "for name in datasets_names:\n",
    "    print(\"******** Exp :\", name, \"**************\")\n",
    "    print(\"Partition\", \"%_class\", \"%_red\", \"Fit\", \"T\")\n",
    "    mean_t = []\n",
    "    mean_fit = []\n",
    "    mean_class = []\n",
    "    mean_red = []\n",
    "    for i in range(5):\n",
    "        train = pd.DataFrame()\n",
    "        test = pd.DataFrame()\n",
    "        data_name = name\n",
    "        train, test = load_df(data_name, i+1)\n",
    "\n",
    "        X_train = train\n",
    "        if name == 'diabetes':\n",
    "            y_train = train['class'].astype(int)\n",
    "            X_train = X_train.drop(columns = ['class'])\n",
    "        else:\n",
    "            y_train = train['Class'].astype(int)\n",
    "            X_train = X_train.drop(columns = ['Class'])\n",
    "\n",
    "        x_test = test\n",
    "        if name == 'diabetes':\n",
    "            y_test = test['class'].astype(int)\n",
    "            x_test = x_test.drop(columns = ['class'])\n",
    "        else:\n",
    "            y_test = test['Class'].astype(int)\n",
    "            x_test = x_test.drop(columns = ['Class'])\n",
    "        \n",
    "        inicio = time.time()\n",
    "        w = np.random.uniform(0, 1, X_train.shape[1])\n",
    "        \n",
    "        if using == 'greedy':\n",
    "            w_bl = greedy(X_train.copy(), y_train.copy())\n",
    "        elif using == 'busqueda_local':\n",
    "            w_bl,a,b = busqueda_local(X_train.copy(), y_train.copy(), w.copy(), 0.0, 15000)\n",
    "        elif using == 'knn':\n",
    "            w_bl = np.ones(X_train.shape[1])\n",
    "    \n",
    "        y_pred = validar_knn(X_train.copy(), y_train.copy(), x_test.copy(), w_bl)\n",
    "        fin = time.time()\n",
    "        tiempo = (fin-inicio)\n",
    "        class_v, red_v, f_value = func(y_test.copy(), y_pred.copy(), w_bl)\n",
    "        print( i + 1, \",\", class_v , \",\" , red_v, \",\", f_value, \",\", tiempo)\n",
    "        mean_fit.append(f_value)\n",
    "        mean_t.append(tiempo)\n",
    "        mean_class.append(class_v)\n",
    "        mean_red.append(red_v)\n",
    "\n",
    "    print(\"Media %class\", np.array(mean_class).mean())\n",
    "    print(\"Media %red\", np.array(mean_red).mean())\n",
    "    print(\"Media fitness\", np.array(mean_fit).mean())\n",
    "    print(\"Media tiempo\", np.array(mean_t).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f8d01660-0a10-4c57-9f18-4de17331def4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.125 , 38.88888888888889 , 70.27777777777777\n",
      "81.25 , 40.27777777777778 , 73.05555555555556\n",
      "82.8125 , 34.72222222222222 , 73.19444444444444\n",
      "73.4375 , 30.555555555555557 , 64.86111111111111\n",
      "82.8125 , 34.72222222222222 , 73.19444444444444\n"
     ]
    }
   ],
   "source": [
    "name = 'ozone-320'\n",
    "np.random.seed(0)\n",
    "\n",
    "for i in range(5):\n",
    "    train = pd.DataFrame()\n",
    "    test = pd.DataFrame()\n",
    "    data_name = name\n",
    "    train, test = load_df(data_name, i+1)\n",
    "\n",
    "    X_train = train\n",
    "    if name == 'diabetes':\n",
    "        y_train = train['class'].astype(int)\n",
    "        X_train = X_train.drop(columns = ['class'])\n",
    "    else:\n",
    "        y_train = train['Class'].astype(int)\n",
    "        X_train = X_train.drop(columns = ['Class'])\n",
    "\n",
    "    x_test = test\n",
    "    if name == 'diabetes':\n",
    "        y_test = test['class'].astype(int)\n",
    "        x_test = x_test.drop(columns = ['class'])\n",
    "    else:\n",
    "        y_test = test['Class'].astype(int)\n",
    "        x_test = x_test.drop(columns = ['Class'])\n",
    "\n",
    "    w_bl = agg(X_train.copy(), y_train.copy(), tipo_cruce = 1)\n",
    "    y_pred = validar_knn(X_train.copy(), y_train.copy(), x_test.copy(), w_bl)\n",
    "\n",
    "\n",
    "    class_v, red_v, f_value = func(y_test.copy(), y_pred.copy(), w_bl)\n",
    "    print(class_v , \",\" , red_v, \",\", f_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e1023b-1390-4cd4-81f3-202094cec40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def operar_cruces(tipo_cruce , next_gen, n_esperado_cruces):\n",
    "    p_cru = 0.7\n",
    "    if tipo_cruce == 1:\n",
    "        alpha = 0.3\n",
    "        iterator = 0\n",
    "        while iterator < n_esperado_cruces:\n",
    "            w_cru_1 = []\n",
    "            w_cru_2 = []\n",
    "            for j in range(len(next_gen[iterator])):\n",
    "                cmax = max(next_gen[iterator][j], next_gen[iterator+1][j])\n",
    "                cmin = min(next_gen[iterator][j], next_gen[iterator+1][j])\n",
    "                i_cru = cmax - cmin\n",
    "                w_cru_1.append(random.uniform(cmin - i_cru * alpha, cmax + i_cru * alpha))\n",
    "                w_cru_2.append(random.uniform(cmin - i_cru * alpha, cmax + i_cru * alpha))\n",
    "\n",
    "            w_cru_1 = np.array(w_cru_1)\n",
    "            w_cru_1[w_cru_1 > 1] = 1\n",
    "            w_cru_1[w_cru_1 < 0] = 0\n",
    "            next_gen[iterator] = w_cru_1.copy()\n",
    "            w_cru_2 = np.array(w_cru_2)\n",
    "            w_cru_2[w_cru_2 > 1] = 1\n",
    "            w_cru_2[w_cru_2 < 0] = 0\n",
    "            next_gen[iterator+1] = w_cru_2.copy()\n",
    "            \n",
    "            iterator = iterator + 2\n",
    "\n",
    "    elif tipo_cruce == 2:\n",
    "        #Cruce aritmetico\n",
    "        for i in range(0,n_esperado_cruces,2):\n",
    "            alpha = np.random.uniform(0, 1)\n",
    "            w_cru_1 = alpha * next_gen[i] + (1-alpha) * next_gen[i + 1]\n",
    "            w_cru_2 = alpha * next_gen[i+1] + (1-alpha) * next_gen[i]\n",
    "\n",
    "            w_cru_1 = np.array(w_cru_1)\n",
    "            w_cru_1[w_cru_1 > 1] = 1\n",
    "            w_cru_1[w_cru_1 < 0] = 0\n",
    "            next_gen[i] = w_cru_1.copy()\n",
    "                \n",
    "            w_cru_2 = np.array(w_cru_2)\n",
    "            w_cru_2[w_cru_2 > 1] = 1\n",
    "            w_cru_2[w_cru_2 < 0] = 0\n",
    "            next_gen[i+1] = w_cru_2.copy()\n",
    "    \n",
    "    return next_gen\n",
    "\n",
    "def agg(X_train, y_train, tipo_cruce):\n",
    "    ws = []\n",
    "    ws_fitness = []\n",
    "    vecinos = 50\n",
    "    iter_ = 0\n",
    "    max_iters = 15000\n",
    "    #Generamos los primeros 50 cromosomas\n",
    "    for i in range(vecinos):\n",
    "        w = np.random.uniform(0, 1, X_train.shape[1])\n",
    "        y_pred = validar_knn_train(X_train.copy(), y_train.copy(), np.array(w))\n",
    "        class_v, red_v, f_value = func(y_train.copy(), y_pred, np.array(w))    \n",
    "        ws.append(w)\n",
    "        ws_fitness.append(f_value)\n",
    "        \n",
    "    while iter_ < max_iters:\n",
    "        \n",
    "        next_gen = []\n",
    "        next_gen_fitness = []\n",
    "           \n",
    "        # Escogemos los padres\n",
    "        for i in range(vecinos):\n",
    "            i_1 = random.randint(0, len(ws)-1)\n",
    "            i_2 = random.randint(0, len(ws)-1)\n",
    "\n",
    "            if ws_fitness[i_1] > ws_fitness[i_2]:\n",
    "                next_gen.append(ws[i_1])\n",
    "            else:\n",
    "                next_gen.append(ws[i_2])\n",
    "  \n",
    "\n",
    "        #Cruzamos los padres\n",
    "        #Cruce blx\n",
    "        new_next_gen = operar_cruces(tipo_cruce, next_gen.copy(), int(0.7 * vecinos))\n",
    "\n",
    "        #Mutamos\n",
    "        numero_mutados = int(len(new_next_gen) * 0.1)\n",
    "        for i in range(numero_mutados):\n",
    "            i_1 = random.randint(0, len(new_next_gen)-1)\n",
    "            \n",
    "            columns_t = np.arange(len(X_train.columns))\n",
    "        \n",
    "            np.random.shuffle(columns_t)\n",
    "            s = np.random.normal(0, 0.3)\n",
    "\n",
    "            new_next_gen[i_1][columns_t[0]] += s\n",
    "\n",
    "            if  new_next_gen[i_1][columns_t[0]] > 1:\n",
    "                new_next_gen[i_1][columns_t[0]] = 1\n",
    "                \n",
    "\n",
    "        # AQUI REEVALUAMOS LA NUEVAMOS TODA LA NUEVA POBLACION\n",
    "        # ITERACIONES += 50\n",
    "        for i in range(vecinos):\n",
    "            y_pred = validar_knn_train(X_train.copy(), y_train.copy(), np.array(new_next_gen[i]))\n",
    "            class_v, red_v, f_value = func(y_train.copy(), y_pred, np.array(new_next_gen[i]))    \n",
    "            next_gen_fitness.append(f_value)\n",
    "            \n",
    "        iter_ += 50\n",
    "        \n",
    "        #Si la mejor solucion de la familia anterior no esta en la siguiente generacion\n",
    "        #sustituimos la peor de la actual generacion por la mejor de la anterior\n",
    "      \n",
    "        idx_worst = np.where(next_gen_fitness == np.min(next_gen_fitness))[0][0]\n",
    "        idx_best = np.where(ws_fitness == np.max(ws_fitness))[0][0]\n",
    "  \n",
    "        if abs((new_next_gen[idx_worst] - ws[idx_best]).sum()) > 0:\n",
    "            new_next_gen[idx_worst] = ws[idx_best]\n",
    "            next_gen_fitness[idx_worst] = ws_fitness[idx_best]\n",
    "           \n",
    "        ws = new_next_gen.copy()\n",
    "        ws_fitness = next_gen_fitness.copy()\n",
    "    \n",
    "    idx_best = np.where(ws_fitness == np.max(ws_fitness))[0][0]\n",
    "\n",
    "    return ws[idx_best]\n",
    "\n",
    "\n",
    "\n",
    "def age(X_train, y_train, tipo_cruce):\n",
    "    ws = []\n",
    "    ws_fitness = []\n",
    "    vecinos = 50\n",
    "    iter_ = 0\n",
    "    max_iters = 15000\n",
    "    \n",
    "    #Generamos los primeros 50 cromosomas\n",
    "    for i in range(vecinos):\n",
    "        w = np.random.uniform(0, 1, X_train.shape[1])\n",
    "        y_pred = validar_knn_train(X_train.copy(), y_train.copy(), np.array(w))\n",
    "        class_v, red_v, f_value = func(y_train.copy(), y_pred, np.array(w))    \n",
    "        ws.append(w)\n",
    "        ws_fitness.append(f_value)\n",
    "\n",
    "    while iter_ < max_iters:\n",
    "        \n",
    "        next_gen = []\n",
    "        dict_arr = {}\n",
    "        \n",
    "        for i in range(len(ws)):\n",
    "            i_1 = random.randint(0, len(ws)-1)\n",
    "            i_2 = random.randint(0, len(ws)-1)\n",
    "\n",
    "            if ws_fitness[i_1] > ws_fitness[i_2]:\n",
    "                next_gen.append(ws[i_1])\n",
    "            else:\n",
    "                next_gen.append(ws[i_2])\n",
    "                \n",
    "\n",
    "        #Cruzamos los padres\n",
    "        next_gen = operar_cruces(tipo_cruce, next_gen, len(next_gen))\n",
    "        \n",
    "        s = np.random.normal(0, 0.3)\n",
    "        #Mutamos\n",
    "        for i in range(len(next_gen)):\n",
    "            probability = np.random.uniform(0, 1)\n",
    "\n",
    "            if probability <= 0.1:\n",
    "                columns_t = np.arange(len(X_train.columns))\n",
    "\n",
    "                np.random.shuffle(columns_t)\n",
    "                s = np.random.normal(0, 0.3)\n",
    "\n",
    "                next_gen[i][columns_t[0]] += s\n",
    "\n",
    "                if  next_gen[i][columns_t[0]] > 1:\n",
    "                    next_gen[i][columns_t[0]] = 1\n",
    "                \n",
    "        #Nos quedamos con los dos mejores a continuacion\n",
    "        for i in range(2):\n",
    "            y_pred = validar_knn_train(X_train.copy(), y_train.copy(), np.array(next_gen[i]))\n",
    "            class_v, red_v, f_value = func(y_train.copy(), y_pred, np.array(next_gen[i]))    \n",
    "            dict_arr[i-2] = f_value\n",
    "                                                                                                              \n",
    "        iter_ += 2\n",
    "        \n",
    "        idx_worst, idx_worst_2 = np.argpartition(ws_fitness, 1)[0:2] \n",
    "        \n",
    "        \n",
    "        dict_arr[idx_worst] = ws_fitness[idx_worst]\n",
    "        dict_arr[idx_worst_2] = ws_fitness[idx_worst_2]\n",
    "        \n",
    "        #print(dict_arr)\n",
    "        \n",
    "        sorted(dict_arr.items(), key=lambda item: item[1], reverse=True)\n",
    "        \n",
    "        keysList = list(dict_arr.keys())\n",
    "        changed = False\n",
    "        for idx in range(2):\n",
    "            if keysList[idx] < 0:\n",
    "                if keysList[idx + 2] > 0 and changed == False:\n",
    "                    ws[keysList[idx + 2]] = next_gen[keysList[idx]].copy()\n",
    "                    ws_fitness[keysList[idx + 2]] = dict_arr[keysList[idx]]\n",
    "                    changed = True\n",
    "                elif keysList[idx + 2] < 0 or changed == False:\n",
    "                    ws[keysList[idx + 3]] = next_gen[keysList[idx]].copy()\n",
    "                    ws_fitness[keysList[idx + 3]] = dict_arr[keysList[idx]]\n",
    "\n",
    "    \n",
    "    idx_best = np.where(ws_fitness == np.max(ws_fitness))[0][0]\n",
    "\n",
    "    return ws[idx_best]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "90225f47-650e-433e-8d8c-8026ceed27c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.42857142857143 , 12.5 , 59.642857142857146\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8e9b293e-7e29-4a74-8343-67e0e97a1034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.39473684210526 , 37.5 , 63.81578947368421\n"
     ]
    }
   ],
   "source": [
    "w_bl = age(X_train.copy(), y_train.copy(), tipo_cruce = 1)\n",
    "\n",
    "y_pred = validar_knn_train(x_test.copy(), y_test.copy(), w_bl)\n",
    "class_v, red_v, f_value = func(y_test.copy(), y_pred.copy(), w_bl)\n",
    "print(class_v , \",\" , red_v, \",\", f_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdffa080-1914-4aa9-b52c-5a4097721999",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([1,0,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b133a32b-8f88-42d8-94a9-932f09bcfec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1137e46-2789-422e-a35e-037369c65077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n"
     ]
    }
   ],
   "source": [
    "print(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39ad659-0cef-40f8-87f5-25dce1be7d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
