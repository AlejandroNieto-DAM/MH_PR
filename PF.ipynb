{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3bc5b2bc-6b09-4bc4-8256-9a3b23d69b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io.arff import loadarff \n",
    "import time\n",
    "import math\n",
    "import scipy.spatial.distance as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "080eb119-d9b4-499d-a5b2-32e05dfa7234",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CARGAR LOS DATOS\n",
    "def load_df(data_name, ind):\n",
    "    train_set = pd.DataFrame()\n",
    "    test_set = pd.DataFrame()\n",
    "    i = ind\n",
    "    a = [1,2,3,4,5]\n",
    "    # print from ind-th index to (n+i)th index.\n",
    "    while i < 5 + (ind - 1):\n",
    "        txt = 'Instancias_APC/{d_name}_{n_data}.arff'\n",
    "        #print(txt.format(d_name = data_name, n_data = a[i % 5]))\n",
    "        raw_data = loadarff(txt.format(d_name = data_name, n_data = a[i % 5]))\n",
    "        raw_df_data = pd.DataFrame(raw_data[0])\n",
    "        train_set = pd.concat([train_set, raw_df_data], ignore_index=True)\n",
    "        i = i + 1\n",
    "        \n",
    "    \n",
    "    raw_data = loadarff(txt.format(d_name = data_name, n_data = ind))\n",
    "    raw_df_data = pd.DataFrame(raw_data[0])\n",
    "    test_set = pd.concat([test_set, raw_df_data], ignore_index=True)\n",
    "    \n",
    "    columns = train_set.columns[:-1] \n",
    "    for column in columns:\n",
    "        min_value = min(test_set[column].min(),train_set[column].min())\n",
    "        max_value = max(test_set[column].max(),train_set[column].max())\n",
    "        train_set[column] = (train_set[column] - min_value) / (max_value - min_value)\n",
    "        test_set[column] = (test_set[column] - min_value) / (max_value - min_value)\n",
    "    \n",
    "\n",
    "    if data_name == 'diabetes':\n",
    "        \n",
    "        values = train_set['class'].unique()\n",
    "        train_set.loc[train_set['class'] == values[0], 'class'] = 0\n",
    "        train_set.loc[train_set['class'] == values[1], 'class'] = 1\n",
    "        test_set.loc[test_set['class'] == values[0], 'class'] = 0\n",
    "        test_set.loc[test_set['class'] == values[1], 'class'] = 1\n",
    "        \n",
    "    return train_set, test_set\n",
    "\n",
    "def busqueda_local(X_train, y_train, w, f_value, max_iter, k = 1):\n",
    "    iter_c = 0\n",
    "    iter_eval = 0\n",
    "    \n",
    "    columns_t = np.arange(len(X_train.columns))\n",
    "    \n",
    "    max_eval = 20 * len(X_train.columns)\n",
    "\n",
    "    best_f_value = f_value\n",
    "    best_w = w.copy()\n",
    "    \n",
    "    while iter_c < max_iter and iter_eval < max_eval:\n",
    "        \n",
    "        if (len(columns_t) < k ):\n",
    "            columns_t = np.arange(len(X_train.columns))\n",
    "\n",
    "        np.random.shuffle(columns_t)\n",
    "        \n",
    "        w_new = best_w.copy()\n",
    "        \n",
    "        \n",
    "        for i in range(k):\n",
    "            s = np.random.normal(loc = 0, scale = 0.3)\n",
    "            w_new[columns_t[i]] += s\n",
    "            \n",
    "        w_new[w_new > 1] = 1\n",
    "        w_new[w_new < 0.1] = 0\n",
    "        \n",
    "        y_pred = validar_knn_train(X_train.copy(), y_train.copy(), w_new.copy())\n",
    "        class_v, red_v, f_value_new = func(y_train.copy(), y_pred.copy(), w_new.copy())\n",
    "        \n",
    "        if f_value_new > best_f_value:\n",
    "            best_w = w_new.copy()\n",
    "            best_f_value = f_value_new\n",
    "            iter_eval = 0\n",
    "        else:\n",
    "            iter_eval += 1\n",
    "        \n",
    "        for i in range(k):\n",
    "            columns_t = np.delete(columns_t, 0)\n",
    "        \n",
    "        iter_c += 1\n",
    "                \n",
    "    return best_w, best_f_value, iter_c\n",
    "\n",
    "\n",
    "\n",
    "def validar_knn(X_train, y_train, x_test, w_true):\n",
    "    w = np.array(w_true.copy())\n",
    "    X_train_p = pd.concat([X_train, x_test], ignore_index=True)\n",
    "    dm = dt.pdist(X_train_p, metric = \"euclidean\", w = w)\n",
    "    a = pd.DataFrame(dt.squareform(dm)) \n",
    "    indexes = a.loc[X_train.shape[0]:, :X_train.shape[0] - 1].idxmin(axis=1)\n",
    "    y_pred = y_train[indexes].values\n",
    "    return y_pred\n",
    "\n",
    "def validar_knn_train(X_train, y_train, w_true):\n",
    "    w = np.array(w_true.copy())\n",
    "    y_pred = np.zeros(len(y_train))\n",
    "    dm = dt.pdist(X_train, metric = \"euclidean\", w = w)\n",
    "    a = pd.DataFrame(dt.squareform(dm))\n",
    "    np.fill_diagonal(a.values, 99999)\n",
    "    indexes = a.idxmin(axis = 1)\n",
    "    y_pred = y_train[indexes].values \n",
    "    return y_pred\n",
    "    \n",
    "def func(y_true, y_pred, w_true):\n",
    "    w = np.array(w_true.copy())\n",
    "    arr_p = np.where((y_true-y_pred) == 0)\n",
    "    aciertos = len(arr_p[0])\n",
    "    \n",
    "    tasa_class = 100.0*(aciertos/len(y_true))\n",
    "    tasa_red = 100.0*(len(w[w<0.1])/len(w))\n",
    "\n",
    "    return tasa_class, tasa_red, 0.8*tasa_class + 0.2*tasa_red\n",
    "\n",
    "def funcion_eval(X_train, y_train, w_new):\n",
    "    y_pred = validar_knn_train(X_train.copy(), y_train.copy(), w_new.copy())\n",
    "    class_v, red_v, f_value_new = func(y_train.copy(), y_pred.copy(), w_new.copy())\n",
    "    return f_value_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93c9529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fish():\n",
    "\n",
    "    def __init__(self, positions, iterations_number, hybrid, X_train, y_train):\n",
    "        self.current_position = positions\n",
    "        self.weight = iterations_number / 2.0\n",
    "        self.fitness = 0\n",
    "        self.delta_fitness = 0\n",
    "        self.delta_position = []\n",
    "\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.hybrid = hybrid\n",
    "        self.X = 60\n",
    "        self.tasa_decrecimiento = 0.05\n",
    "        self.tiempo = 2\n",
    "\n",
    "    def evaluate(self):\n",
    "        new_fitness = funcion_eval(self.X_train.copy(), self.y_train.copy(), self.current_position)\n",
    "        self.fitness = new_fitness\n",
    "\n",
    "    def update_position_individual_movement(self, step_ind):\n",
    "        new_positions = []\n",
    "        for pos in self.current_position:\n",
    "            new = pos + (step_ind * np.random.uniform(-1, 1))\n",
    "            if new > 1:\n",
    "                new = 1\n",
    "            elif new < 0:\n",
    "                new = 0\n",
    "            new_positions.append(new)\n",
    "        assert len(new_positions) == len(self.current_position)\n",
    "\n",
    "        new_fitness = funcion_eval(self.X_train.copy(), self.y_train.copy(), new_positions)\n",
    "\n",
    "        self.X = self.X * math.exp(-self.tasa_decrecimiento * self.tiempo)\n",
    "        \n",
    "        if new_fitness > self.fitness:\n",
    "            self.delta_fitness = abs(new_fitness - self.fitness)\n",
    "            self.fitness = new_fitness\n",
    "            self.delta_position = [x - y for x, y in zip(new_positions, self.current_position)]\n",
    "            self.current_position = list(new_positions)\n",
    "        else:\n",
    "            self.delta_position = [0] * len(self.current_position)\n",
    "            self.delta_fitness = 0\n",
    "\n",
    "    def feed(self, max_delta_fitness):\n",
    "        if max_delta_fitness != 0:\n",
    "            self.weight = self.weight + (self.delta_fitness / max_delta_fitness)\n",
    "        else:\n",
    "            self.weight = 1\n",
    "\n",
    "    def update_position_collective_movement(self, sum_delta_fitness):\n",
    "        collective_instinct = []\n",
    "        for i, _ in enumerate(self.delta_position):\n",
    "            collective_instinct.append(self.delta_position[i] * self.delta_fitness)\n",
    "        if sum_delta_fitness != 0:\n",
    "            collective_instinct = [val / sum_delta_fitness for val in collective_instinct]\n",
    "\n",
    "        new_positions = []\n",
    "        for i, _ in enumerate(self.current_position):\n",
    "            new = self.current_position[i] + collective_instinct[i]\n",
    "            if new > 1:\n",
    "                new = 1\n",
    "            elif new < 0:\n",
    "                new = 0\n",
    "            new_positions.append(new)\n",
    "\n",
    "        assert len(new_positions) == len(self.current_position)\n",
    "        self.current_position = list(new_positions)\n",
    "\n",
    "    def update_position_volitive_movement(self, barycenter, step_vol, search_operator):\n",
    "        new_positions = []\n",
    "        for i, pos in enumerate(self.current_position):\n",
    "            new = pos + (((pos - barycenter[i]) * step_vol * np.random.uniform(0, 1)) * search_operator)\n",
    "            if new > 1:\n",
    "                new = 1\n",
    "            elif new < 0:\n",
    "                new = 0\n",
    "            new_positions.append(new)\n",
    "\n",
    "        assert len(new_positions) == len(self.current_position)\n",
    "        self.current_position = list(new_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87148969",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSS():\n",
    "\n",
    "    def __init__(self, iterations_number, num_of_individuos, dimensions, hybrid, improve, X_train, y_train):\n",
    "       \n",
    "        self.dimensions = dimensions\n",
    "        self.iterations_number = iterations_number\n",
    "        self.num_of_individuos = num_of_individuos\n",
    "        self.cluster = []\n",
    "        self.global_best = float(0)\n",
    "        self.global_best_position = []\n",
    "\n",
    "        # Params\n",
    "        self.total_weight = 1 * self.num_of_individuos\n",
    "        self.initial_step_ind = 0.1\n",
    "        self.final_step_ind = 0.00001\n",
    "        self.step_ind = self.initial_step_ind \n",
    "        self.initial_step_vol = 0.01\n",
    "        self.final_step_vol = 0.001\n",
    "        self.step_vol = self.initial_step_vol \n",
    "        self.list_global_best_values = []\n",
    "\n",
    "        self.hybrid = hybrid\n",
    "        self.improve = improve\n",
    "        self.iter = 1\n",
    "        self.generation = 1\n",
    "\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def search(self):\n",
    "        self._initialize_cluster()\n",
    "\n",
    "        while self.iter <= self.iterations_number:\n",
    "            self.evaluate_cluster()\n",
    "            self.updates_optimal_solution()\n",
    "\n",
    "            self.apply_individual_movement()\n",
    "            self.evaluate_cluster()\n",
    "            self.updates_optimal_solution()\n",
    "\n",
    "            self.apply_feeding()\n",
    "            self.apply_instintive_collective_movement()\n",
    "            self.apply_collective_volitive_movement()\n",
    "            \n",
    "\n",
    "            if self.hybrid == True:\n",
    "                fit_fish = []\n",
    "                for fish in self.cluster:\n",
    "                    fit_fish.append(fish.fitness)\n",
    "                index_best = np.argpartition(fit_fish, -5)[:-5]\n",
    "                for index in index_best:\n",
    "                    w_bl, f, iter = busqueda_local(self.X_train, self.y_train, np.array(self.cluster[index].current_position), self.cluster[index].fitness, 400)\n",
    "                    self.iter += iter\n",
    "                    self.cluster[index].current_position = w_bl\n",
    "                    self.cluster[index].fitness = f\n",
    "            \n",
    "            self.update_step(self.iter)\n",
    "            self.update_total_weight()\n",
    "\n",
    "            if self.improve == True:\n",
    "                fit_fish = []\n",
    "                for fish in self.cluster:\n",
    "                    fit_fish.append(fish.fitness)\n",
    "\n",
    "                index_best = np.argpartition(fit_fish, 5)[:5]\n",
    "\n",
    "                for new_fish_in_index in index_best:\n",
    "                    fish = Fish(\n",
    "                    positions=[self._get_random_number() for _ in range(self.dimensions)],\n",
    "                    iterations_number = self.iterations_number,\n",
    "                    hybrid = self.hybrid,\n",
    "                    X_train = self.X_train.copy(),\n",
    "                    y_train = self.y_train.copy()\n",
    "                    )\n",
    "                    self.cluster[new_fish_in_index] = fish\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            self.iter += 2 * self.num_of_individuos\n",
    "            \n",
    "        self.evaluate_cluster()\n",
    "        self.updates_optimal_solution()\n",
    "\n",
    "    def update_total_weight(self):\n",
    "        self.total_weight = sum([fish.weight for fish in self.cluster])\n",
    "\n",
    "    def _initialize_cluster(self):\n",
    "        self.cluster = []\n",
    "        \n",
    "        for _ in range(self.num_of_individuos):\n",
    "            fish = Fish(\n",
    "                positions=[self._get_random_number() for _ in range(self.dimensions)],\n",
    "                iterations_number = self.iterations_number,\n",
    "                hybrid = self.hybrid,\n",
    "                X_train = self.X_train.copy(),\n",
    "                y_train = self.y_train.copy()\n",
    "            )\n",
    "            self.cluster.append(fish)\n",
    "\n",
    "    def evaluate_cluster(self):\n",
    "        for fish in self.cluster:\n",
    "            fish.evaluate()\n",
    "        \n",
    "    def updates_optimal_solution(self):\n",
    "\n",
    "        for fish in self.cluster:\n",
    "            if fish.fitness > self.global_best:\n",
    "                self.global_best = fish.fitness\n",
    "                self.global_best_position = list(fish.current_position.copy())\n",
    "                self.generation = 0\n",
    "            self.generation += 1\n",
    "            \n",
    "\n",
    "    def apply_individual_movement(self):\n",
    "        for fish in self.cluster:\n",
    "            fish.update_position_individual_movement(self.step_ind)\n",
    "\n",
    "    def apply_feeding(self):\n",
    "        max_delta_fitness = max([fish.delta_fitness for fish in self.cluster])\n",
    "        for fish in self.cluster:\n",
    "            fish.feed(max_delta_fitness)\n",
    "\n",
    "    def apply_instintive_collective_movement(self):\n",
    "        sum_delta_fitness = sum([fish.delta_fitness for fish in self.cluster])\n",
    "\n",
    "        for fish in self.cluster:\n",
    "            fish.update_position_collective_movement(sum_delta_fitness)\n",
    "\n",
    "    def _calculate_barycenter(self):\n",
    "        sum_weights = sum([fish.weight for fish in self.cluster])\n",
    "        sum_position_and_weights = [[x * fish.weight for x in fish.current_position] for fish in self.cluster]\n",
    "        sum_position_and_weights = np.sum(sum_position_and_weights, 0)\n",
    "        return [s / sum_weights for s in sum_position_and_weights]\n",
    "\n",
    "    def apply_collective_volitive_movement(self):\n",
    "        barycenter = self._calculate_barycenter()\n",
    "        current_total_weight = sum([fish.weight for fish in self.cluster])\n",
    "        search_operator = -1 if current_total_weight > self.total_weight else 1\n",
    "        for fish in self.cluster:\n",
    "            fish.update_position_volitive_movement(barycenter, self.step_vol, search_operator)\n",
    "\n",
    "    def update_step(self, current_i):\n",
    "        self.step_ind = self.initial_step_ind - current_i * float(self.initial_step_ind - self.final_step_ind) / self.iterations_number\n",
    "        self.step_vol = self.initial_step_vol - current_i * float(self.initial_step_vol - self.final_step_vol) / self.iterations_number\n",
    "\n",
    "    def _get_random_number(self):\n",
    "        return np.random.uniform(0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "36c94e36-6db4-4c55-8ee6-22aac9f56cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** Exp : diabetes **************\n",
      "Partition %_class %_red Fit T\n",
      "1 ; 65.5844155844156 ; 75.0 ; 67.46753246753248 ; 177.2091064453125\n",
      "2 ; 66.23376623376623 ; 62.5 ; 65.48701298701299 ; 109.56760740280151\n",
      "3 ; 61.68831168831169 ; 87.5 ; 66.85064935064935 ; 106.813800573349\n",
      "4 ; 66.23376623376623 ; 75.0 ; 67.98701298701299 ; 133.7906756401062\n",
      "5 ; 69.07894736842105 ; 75.0 ; 70.26315789473685 ; 100.20603919029236\n",
      "Media; 65.76384142173615 ; 75.0 ; 67.61107313738894 ; 125.51744585037231\n",
      "******** Exp : ozone-320 **************\n",
      "Partition %_class %_red Fit T\n",
      "1 ; 78.125 ; 33.33333333333333 ; 69.16666666666667 ; 114.42008972167969\n",
      "2 ; 75.0 ; 41.66666666666667 ; 68.33333333333333 ; 115.31245994567871\n",
      "3 ; 76.5625 ; 33.33333333333333 ; 67.91666666666667 ; 113.45236396789551\n",
      "4 ; 65.625 ; 27.77777777777778 ; 58.05555555555556 ; 118.69585943222046\n",
      "5 ; 79.6875 ; 30.555555555555557 ; 69.86111111111111 ; 120.05683517456055\n",
      "Media; 75.0 ; 33.333333333333336 ; 66.66666666666667 ; 116.38752164840699\n",
      "******** Exp : spectf-heart **************\n",
      "Partition %_class %_red Fit T\n",
      "1 ; 81.42857142857143 ; 47.72727272727273 ; 74.6883116883117 ; 77.78432965278625\n",
      "2 ; 87.14285714285714 ; 43.18181818181818 ; 78.35064935064935 ; 81.3644950389862\n",
      "3 ; 94.28571428571428 ; 38.63636363636363 ; 83.15584415584416 ; 88.9364402294159\n",
      "4 ; 90.0 ; 50.0 ; 82.0 ; 75.20602226257324\n",
      "5 ; 82.6086956521739 ; 43.18181818181818 ; 74.72332015810277 ; 76.68612217903137\n",
      "Media; 87.09316770186335 ; 44.54545454545455 ; 78.58362507058159 ; 79.9954818725586\n"
     ]
    }
   ],
   "source": [
    "# SEMILLA\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "## USO DE FSS HIBRIDADO\n",
    "hibridacion = False \n",
    "\n",
    "## USO DE FSS MEJORADO\n",
    "mejorado = False\n",
    "\n",
    "\n",
    "datasets_names = ['diabetes', 'ozone-320', 'spectf-heart']\n",
    "df_output = pd.DataFrame()\n",
    "\n",
    "for name in datasets_names:\n",
    "    print(\"******** Exp :\", name, \"**************\")\n",
    "    print(\"Partition\", \"%_class\", \"%_red\", \"Fit\", \"T\")\n",
    "    mean_t = []\n",
    "    mean_fit = []\n",
    "    mean_class = []\n",
    "    mean_red = []\n",
    "    final_df = []  \n",
    "\n",
    "    for i in range(5):   \n",
    "\n",
    "        train = pd.DataFrame()\n",
    "        test = pd.DataFrame()\n",
    "        data_name = name\n",
    "        train, test = load_df(data_name, i+1)\n",
    "\n",
    "        X_train = train\n",
    "        if name == 'diabetes':\n",
    "            y_train = train['class'].astype(int)\n",
    "            X_train = X_train.drop(columns = ['class'])\n",
    "        else:\n",
    "            y_train = train['Class'].astype(int)\n",
    "            X_train = X_train.drop(columns = ['Class'])\n",
    "\n",
    "        x_test = test\n",
    "        if name == 'diabetes':\n",
    "            y_test = test['class'].astype(int)\n",
    "            x_test = x_test.drop(columns = ['class'])\n",
    "        else:\n",
    "            y_test = test['Class'].astype(int)\n",
    "            x_test = x_test.drop(columns = ['Class'])\n",
    "\n",
    "\n",
    "        inicio = time.time()\n",
    "\n",
    "        fss = FSS(iterations_number = 15000, num_of_individuos = 50, dimensions = X_train.shape[1], hybrid=hibridacion, improve = mejorado, X_train=X_train.copy(), y_train=y_train.copy())\n",
    "        fss.search()\n",
    "        \n",
    "        w_bl = fss.global_best_position        \n",
    "\n",
    "        fin = time.time()\n",
    "        tiempo = (fin-inicio)\n",
    "\n",
    "        y_pred = validar_knn(X_train.copy(), y_train.copy(), x_test.copy(), w_bl)\n",
    "        class_v, red_v, f_value = func(y_test.copy(), y_pred.copy(), w_bl)\n",
    "\n",
    "        metrics = []\n",
    "        metrics.append(class_v)\n",
    "        metrics.append(red_v)\n",
    "        metrics.append(f_value)\n",
    "        metrics.append(tiempo)\n",
    "\n",
    "        print(i + 1, \";\", class_v , \";\" , red_v, \";\", f_value, \";\", tiempo)\n",
    "        mean_fit.append(f_value)\n",
    "        mean_t.append(tiempo)\n",
    "        mean_class.append(class_v)\n",
    "        mean_red.append(red_v)\n",
    "\n",
    "        final_df.append(metrics)\n",
    "\n",
    "    print(\"Media;\", np.array(mean_class).mean(), \";\", np.array(mean_red).mean(), \";\", np.array(mean_fit).mean(), \";\", np.array(mean_t).mean())\n",
    "\n",
    "    metrics = []\n",
    "    metrics.append( np.array(mean_class).mean())\n",
    "    metrics.append(np.array(mean_red).mean())\n",
    "    metrics.append(np.array(mean_fit).mean())\n",
    "    metrics.append(np.array(mean_t).mean())\n",
    "    final_df.append(metrics)\n",
    "\n",
    "    df = pd.DataFrame(final_df, columns = [\"%class\", \"%red\", \"fit\", \"T\"], index = [\"P1\", \"P2\", \"P3\", \"P4\", \"P5\", \"MEDIA\"])\n",
    "    df_output = pd.concat([df_output, df], axis= 1)\n",
    "\n",
    "#with pd.ExcelWriter('MetricasMH.xlsx', engine=\"openpyxl\", mode='a') as writer:  \n",
    "#    df_output.to_excel(writer, sheet_name=\"FFS_bi\")\n",
    "\n",
    "#print(df_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65987e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
