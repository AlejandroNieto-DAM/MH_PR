{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bc5b2bc-6b09-4bc4-8256-9a3b23d69b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io.arff import loadarff \n",
    "import time\n",
    "import scipy.spatial.distance as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "080eb119-d9b4-499d-a5b2-32e05dfa7234",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CARGAR LOS DATOS\n",
    "def load_df(data_name, ind):\n",
    "    train_set = pd.DataFrame()\n",
    "    test_set = pd.DataFrame()\n",
    "    i = ind\n",
    "    a = [1,2,3,4,5]\n",
    "    # print from ind-th index to (n+i)th index.\n",
    "    while i < 5 + (ind - 1):\n",
    "        txt = 'Instancias_APC/{d_name}_{n_data}.arff'\n",
    "        #print(txt.format(d_name = data_name, n_data = a[i % 5]))\n",
    "        raw_data = loadarff(txt.format(d_name = data_name, n_data = a[i % 5]))\n",
    "        raw_df_data = pd.DataFrame(raw_data[0])\n",
    "        train_set = pd.concat([train_set, raw_df_data], ignore_index=True)\n",
    "        i = i + 1\n",
    "        \n",
    "    \n",
    "    raw_data = loadarff(txt.format(d_name = data_name, n_data = ind))\n",
    "    raw_df_data = pd.DataFrame(raw_data[0])\n",
    "    test_set = pd.concat([test_set, raw_df_data], ignore_index=True)\n",
    "    \n",
    "    columns = train_set.columns[:-1] \n",
    "    for column in columns:\n",
    "        min_value = min(test_set[column].min(),train_set[column].min())\n",
    "        max_value = max(test_set[column].max(),train_set[column].max())\n",
    "        train_set[column] = (train_set[column] - min_value) / (max_value - min_value)\n",
    "        test_set[column] = (test_set[column] - min_value) / (max_value - min_value)\n",
    "    \n",
    "\n",
    "    if data_name == 'diabetes':\n",
    "        \n",
    "        values = train_set['class'].unique()\n",
    "        train_set.loc[train_set['class'] == values[0], 'class'] = 0\n",
    "        train_set.loc[train_set['class'] == values[1], 'class'] = 1\n",
    "        test_set.loc[test_set['class'] == values[0], 'class'] = 0\n",
    "        test_set.loc[test_set['class'] == values[1], 'class'] = 1\n",
    "        \n",
    "    return train_set, test_set\n",
    "\n",
    "## BUSQUEDA LOCAL\n",
    "def busqueda_local(X_train, y_train, w, f_value, max_iter, k = 1):\n",
    "    iter_c = 0\n",
    "    iter_eval = 0\n",
    "    \n",
    "    columns_t = np.arange(len(X_train.columns))\n",
    "    \n",
    "    max_eval = 20 * len(X_train.columns)\n",
    "    \n",
    "    while iter_c < max_iter and iter_eval < max_eval:\n",
    "        \n",
    "        if (len(columns_t) < k ):\n",
    "            columns_t = np.arange(len(X_train.columns))\n",
    "\n",
    "        np.random.shuffle(columns_t)\n",
    "        \n",
    "        w_new = w.copy()\n",
    "        \n",
    "        \n",
    "        for i in range(k):\n",
    "            s = np.random.normal(loc = 0, scale = 0.3)\n",
    "            w_new[columns_t[i]] += s\n",
    "            \n",
    "        w_new[w_new > 1] = 1\n",
    "        w_new[w_new < 0.1] = 0\n",
    "        \n",
    "        y_pred = validar_knn_train(X_train.copy(), y_train.copy(), w_new.copy())\n",
    "        class_v, red_v, f_value_new = func(y_train.copy(), y_pred.copy(), w_new.copy())\n",
    "        \n",
    "        if f_value_new > f_value:\n",
    "            w = w_new.copy()\n",
    "            f_value = f_value_new\n",
    "            iter_eval = 0\n",
    "        else:\n",
    "            iter_eval += 1\n",
    "        \n",
    "        for i in range(k):\n",
    "            columns_t = np.delete(columns_t, 0)\n",
    "        \n",
    "        iter_c += 1\n",
    "                \n",
    "    return w, f_value, iter_c\n",
    "\n",
    "def funcion_eval(X_train, y_train, w_new):\n",
    "    y_pred = validar_knn_train(X_train.copy(), y_train.copy(), w_new.copy())\n",
    "    class_v, red_v, f_value_new = func(y_train.copy(), y_pred.copy(), w_new.copy())\n",
    "    return f_value_new\n",
    "\n",
    "def validar_knn(X_train, y_train, x_test, w_true):\n",
    "    w = np.array(w_true.copy())\n",
    "    X_train_p = pd.concat([X_train, x_test], ignore_index=True)\n",
    "    dm = dt.pdist(X_train_p, metric = \"euclidean\", w = w)\n",
    "    a = pd.DataFrame(dt.squareform(dm)) \n",
    "    indexes = a.loc[X_train.shape[0]:, :X_train.shape[0] - 1].idxmin(axis=1)\n",
    "    y_pred = y_train[indexes].values\n",
    "    return y_pred\n",
    "\n",
    "def validar_knn_train(X_train, y_train, w_true):\n",
    "    w = np.array(w_true.copy())\n",
    "    y_pred = np.zeros(len(y_train))\n",
    "    dm = dt.pdist(X_train, metric = \"euclidean\", w = w)\n",
    "    a = pd.DataFrame(dt.squareform(dm))\n",
    "    np.fill_diagonal(a.values, 99999)\n",
    "    indexes = a.idxmin(axis = 1)\n",
    "    y_pred = y_train[indexes].values \n",
    "    return y_pred\n",
    "    \n",
    "def func(y_true, y_pred, w_true):\n",
    "    w = np.array(w_true.copy())\n",
    "    arr_p = np.where((y_true-y_pred) == 0)\n",
    "    aciertos = len(arr_p[0])\n",
    "    \n",
    "    tasa_class = 100.0*(aciertos/len(y_true))\n",
    "    tasa_red = 100.0*(len(w[w<0.1])/len(w))\n",
    "\n",
    "    return tasa_class, tasa_red, 0.8*tasa_class + 0.2*tasa_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36c94e36-6db4-4c55-8ee6-22aac9f56cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** Exp : diabetes **************\n",
      "Partition %_class %_red Fit T\n",
      "iter: 0 = cost: 63.52605863192182\n",
      "iter: 200 = cost: 70.87133550488599\n",
      "iter: 400 = cost: 73.24104234527687\n",
      "iter: 600 = cost: 76.39250814332247\n",
      "iter: 800 = cost: 76.39250814332247\n",
      "iter: 1000 = cost: 76.78338762214983\n",
      "iter: 1200 = cost: 78.08631921824104\n",
      "iter: 1400 = cost: 79.15309446254072\n",
      "iter: 1600 = cost: 79.15309446254072\n",
      "iter: 1800 = cost: 79.15309446254072\n",
      "iter: 2000 = cost: 79.15309446254072\n",
      "iter: 2200 = cost: 79.15309446254072\n",
      "iter: 2400 = cost: 79.15309446254072\n",
      "iter: 2600 = cost: 79.15309446254072\n",
      "iter: 2800 = cost: 79.15309446254072\n",
      "iter: 3000 = cost: 79.15309446254072\n",
      "iter: 3200 = cost: 79.15309446254072\n",
      "iter: 3400 = cost: 79.15309446254072\n",
      "iter: 3600 = cost: 79.15309446254072\n",
      "iter: 3800 = cost: 79.15309446254072\n",
      "iter: 4000 = cost: 79.15309446254072\n",
      "iter: 4200 = cost: 79.15309446254072\n",
      "iter: 4400 = cost: 79.15309446254072\n",
      "iter: 4600 = cost: 79.15309446254072\n",
      "iter: 4800 = cost: 79.15309446254072\n",
      "1 ; 66.23376623376623 ; 100.0 ; 72.98701298701299 ; 4874.497590780258\n",
      "iter: 0 = cost: 65.63517915309447\n",
      "iter: 200 = cost: 74.17752442996743\n",
      "iter: 400 = cost: 75.35016286644952\n",
      "iter: 600 = cost: 75.87133550488599\n",
      "iter: 800 = cost: 76.80781758957654\n",
      "iter: 1000 = cost: 78.76221498371336\n",
      "iter: 1200 = cost: 79.93485342019545\n",
      "iter: 1400 = cost: 79.93485342019545\n",
      "iter: 1600 = cost: 79.93485342019545\n",
      "iter: 1800 = cost: 79.93485342019545\n",
      "iter: 2000 = cost: 79.93485342019545\n",
      "iter: 2200 = cost: 79.93485342019545\n",
      "iter: 2400 = cost: 79.93485342019545\n",
      "iter: 2600 = cost: 79.93485342019545\n",
      "iter: 2800 = cost: 79.93485342019545\n",
      "iter: 3000 = cost: 79.93485342019545\n",
      "iter: 3200 = cost: 79.93485342019545\n",
      "iter: 3400 = cost: 79.93485342019545\n",
      "iter: 3600 = cost: 79.93485342019545\n",
      "iter: 3800 = cost: 79.93485342019545\n",
      "iter: 4000 = cost: 79.93485342019545\n",
      "iter: 4200 = cost: 79.93485342019545\n",
      "iter: 4400 = cost: 79.93485342019545\n",
      "iter: 4600 = cost: 79.93485342019545\n",
      "iter: 4800 = cost: 79.93485342019545\n",
      "2 ; 67.53246753246754 ; 100.0 ; 74.02597402597402 ; 4908.945795297623\n",
      "iter: 0 = cost: 64.82899022801303\n",
      "iter: 200 = cost: 72.98045602605863\n",
      "iter: 400 = cost: 72.98045602605863\n",
      "iter: 600 = cost: 74.82899022801303\n",
      "iter: 800 = cost: 74.82899022801303\n",
      "iter: 1000 = cost: 76.52280130293161\n",
      "iter: 1200 = cost: 76.52280130293161\n",
      "iter: 1400 = cost: 76.52280130293161\n",
      "iter: 1600 = cost: 76.52280130293161\n",
      "iter: 1800 = cost: 78.37133550488599\n",
      "iter: 2000 = cost: 78.63192182410424\n",
      "iter: 2200 = cost: 78.63192182410424\n",
      "iter: 2400 = cost: 78.63192182410424\n",
      "iter: 2600 = cost: 78.63192182410424\n",
      "iter: 2800 = cost: 78.63192182410424\n",
      "iter: 3000 = cost: 79.41368078175896\n",
      "iter: 3200 = cost: 79.41368078175896\n",
      "iter: 3400 = cost: 79.41368078175896\n",
      "iter: 3600 = cost: 79.41368078175896\n",
      "iter: 3800 = cost: 79.41368078175896\n",
      "iter: 4000 = cost: 79.41368078175896\n",
      "iter: 4200 = cost: 79.41368078175896\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m inicio \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     48\u001b[0m fss \u001b[38;5;241m=\u001b[39m FSS(iterations_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m, num_of_individuos \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m, probability_of_recombination \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.6\u001b[39m, dimensions \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 49\u001b[0m \u001b[43mfss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m w_bl \u001b[38;5;241m=\u001b[39m fss\u001b[38;5;241m.\u001b[39mglobal_best_position\n\u001b[0;32m     53\u001b[0m fin \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36mFSS.search\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_step(i)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_total_weight()\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_cluster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdates_optimal_solution()\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlist_global_best_values\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_best)\n",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36mFSS.evaluate_cluster\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_cluster\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fish \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster:\n\u001b[1;32m--> 140\u001b[0m         \u001b[43mfish\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36mFish.evaluate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 11\u001b[0m     new_fitness \u001b[38;5;241m=\u001b[39m \u001b[43mfuncion_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_position\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness \u001b[38;5;241m=\u001b[39m new_fitness\n",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36mfuncion_eval\u001b[1;34m(X_train, y_train, w_new)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfuncion_eval\u001b[39m(X_train, y_train, w_new):\n\u001b[1;32m---> 83\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mvalidar_knn_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_new\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     class_v, red_v, f_value_new \u001b[38;5;241m=\u001b[39m func(y_train\u001b[38;5;241m.\u001b[39mcopy(), y_pred\u001b[38;5;241m.\u001b[39mcopy(), w_new\u001b[38;5;241m.\u001b[39mcopy())\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f_value_new\n",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36mvalidar_knn_train\u001b[1;34m(X_train, y_train, w_true)\u001b[0m\n\u001b[0;32m     97\u001b[0m w \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(w_true\u001b[38;5;241m.\u001b[39mcopy())\n\u001b[0;32m     98\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(y_train))\n\u001b[1;32m---> 99\u001b[0m dm \u001b[38;5;241m=\u001b[39m \u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meuclidean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m a \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(dt\u001b[38;5;241m.\u001b[39msquareform(dm))\n\u001b[0;32m    101\u001b[0m np\u001b[38;5;241m.\u001b[39mfill_diagonal(a\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m99999\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py:2233\u001b[0m, in \u001b[0;36mpdist\u001b[1;34m(X, metric, out, **kwargs)\u001b[0m\n\u001b[0;32m   2231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2232\u001b[0m     pdist_fn \u001b[38;5;241m=\u001b[39m metric_info\u001b[38;5;241m.\u001b[39mpdist_func\n\u001b[1;32m-> 2233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pdist_fn(X, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2234\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mstr\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   2235\u001b[0m     metric_info \u001b[38;5;241m=\u001b[39m _TEST_METRICS\u001b[38;5;241m.\u001b[39mget(mstr, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datasets_names = ['diabetes', 'ozone-320', 'spectf-heart']\n",
    "\n",
    "# SEMILLA\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "\n",
    "algs = [\"BMB\", \"ILS1\", \"ILS2\", \"VNS\", \"ES\"] \n",
    "\n",
    "for alg in algs:\n",
    "    \n",
    "    df_output = pd.DataFrame()\n",
    "\n",
    "    for name in ['diabetes']:\n",
    "        print(\"******** Exp :\", name, \"**************\")\n",
    "        print(\"Partition\", \"%_class\", \"%_red\", \"Fit\", \"T\")\n",
    "        mean_t = []\n",
    "        mean_fit = []\n",
    "        mean_class = []\n",
    "        mean_red = []\n",
    "        final_df = []  \n",
    "\n",
    "        for i in range(5):   \n",
    "\n",
    "            train = pd.DataFrame()\n",
    "            test = pd.DataFrame()\n",
    "            data_name = name\n",
    "            train, test = load_df(data_name, i+1)\n",
    "\n",
    "            X_train = train\n",
    "            if name == 'diabetes':\n",
    "                y_train = train['class'].astype(int)\n",
    "                X_train = X_train.drop(columns = ['class'])\n",
    "            else:\n",
    "                y_train = train['Class'].astype(int)\n",
    "                X_train = X_train.drop(columns = ['Class'])\n",
    "\n",
    "            x_test = test\n",
    "            if name == 'diabetes':\n",
    "                y_test = test['class'].astype(int)\n",
    "                x_test = x_test.drop(columns = ['class'])\n",
    "            else:\n",
    "                y_test = test['Class'].astype(int)\n",
    "                x_test = x_test.drop(columns = ['Class'])\n",
    "\n",
    "\n",
    "            inicio = time.time()\n",
    "\n",
    "            fss = FSS(iterations_number = 5000, num_of_individuos = 50, probability_of_recombination = 0.6, dimensions = X_train.shape[1])\n",
    "            fss.search()\n",
    "            \n",
    "            w_bl = fss.global_best_position\n",
    "            \n",
    "            fin = time.time()\n",
    "            tiempo = (fin-inicio)\n",
    "\n",
    "            y_pred = validar_knn(X_train.copy(), y_train.copy(), x_test.copy(), w_bl)\n",
    "            class_v, red_v, f_value = func(y_test.copy(), y_pred.copy(), w_bl)\n",
    "\n",
    "            metrics = []\n",
    "            metrics.append(class_v)\n",
    "            metrics.append(red_v)\n",
    "            metrics.append(f_value)\n",
    "            metrics.append(tiempo)\n",
    "\n",
    "            print(i + 1, \";\", class_v , \";\" , red_v, \";\", f_value, \";\", tiempo)\n",
    "            mean_fit.append(f_value)\n",
    "            mean_t.append(tiempo)\n",
    "            mean_class.append(class_v)\n",
    "            mean_red.append(red_v)\n",
    "\n",
    "            final_df.append(metrics)\n",
    "\n",
    "        print(\"Media;\", np.array(mean_class).mean(), \";\", np.array(mean_red).mean(), \";\", np.array(mean_fit).mean(), \";\", np.array(mean_t).mean())\n",
    "\n",
    "        metrics = []\n",
    "        metrics.append( np.array(mean_class).mean())\n",
    "        metrics.append(np.array(mean_red).mean())\n",
    "        metrics.append(np.array(mean_fit).mean())\n",
    "        metrics.append(np.array(mean_t).mean())\n",
    "        final_df.append(metrics)\n",
    "\n",
    "        df = pd.DataFrame(final_df, columns = [\"%class\", \"%red\", \"fit\", \"T\"], index = [\"P1\", \"P2\", \"P3\", \"P4\", \"P5\", \"MEDIA\"])\n",
    "        df_output = pd.concat([df_output, df], axis= 1)\n",
    "\n",
    "    #with pd.ExcelWriter('MetricasMH.xlsx', engine=\"openpyxl\", mode='a') as writer:  \n",
    "        #df_output.to_excel(writer, sheet_name=alg)\n",
    "\n",
    "    #print(df_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a0d2e9ee-9f03-4552-a701-4e65135d2a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Fish():\n",
    "\n",
    "    def __init__(self, positions, iterations_number):\n",
    "        self.current_position = positions\n",
    "        self.weight = iterations_number / 2.0\n",
    "        self.fitness = 0\n",
    "        self.delta_fitness = 0\n",
    "        self.delta_position = []\n",
    "\n",
    "    def evaluate(self):\n",
    "        new_fitness = funcion_eval(X_train, y_train, self.current_position)\n",
    "        self.fitness = new_fitness\n",
    "\n",
    "    def update_position_individual_movement(self, step_ind):\n",
    "        new_positions = []\n",
    "        for pos in self.current_position:\n",
    "            new = pos + (step_ind * np.random.uniform(-1, 1))\n",
    "            if new > 1:\n",
    "                new = 1\n",
    "            elif new < 0:\n",
    "                new = 0\n",
    "            new_positions.append(new)\n",
    "        assert len(new_positions) == len(self.current_position)\n",
    "\n",
    "        new_fitness = funcion_eval(X_train, y_train, new_positions)\n",
    "        if new_fitness > self.fitness:\n",
    "            self.delta_fitness = abs(new_fitness - self.fitness)\n",
    "            self.fitness = new_fitness\n",
    "            self.delta_position = [x - y for x, y in zip(new_positions, self.current_position)]\n",
    "            self.current_position = list(new_positions)\n",
    "        else:\n",
    "            self.delta_position = [0] * len(self.current_position)\n",
    "            self.delta_fitness = 0\n",
    "\n",
    "    def feed(self, max_delta_fitness):\n",
    "        if max_delta_fitness != 0:\n",
    "            self.weight = self.weight + (self.delta_fitness / max_delta_fitness)\n",
    "        else:\n",
    "            self.weight = 1\n",
    "\n",
    "    def update_position_collective_movement(self, sum_delta_fitness):\n",
    "        collective_instinct = []\n",
    "        for i, _ in enumerate(self.delta_position):\n",
    "            collective_instinct.append(self.delta_position[i] * self.delta_fitness)\n",
    "        if sum_delta_fitness != 0:\n",
    "            collective_instinct = [val / sum_delta_fitness for val in collective_instinct]\n",
    "\n",
    "        new_positions = []\n",
    "        for i, _ in enumerate(self.current_position):\n",
    "            new = self.current_position[i] + collective_instinct[i]\n",
    "            if new > 1:\n",
    "                new = 1\n",
    "            elif new < 0:\n",
    "                new = 0\n",
    "            new_positions.append(new)\n",
    "\n",
    "        assert len(new_positions) == len(self.current_position)\n",
    "        self.current_position = list(new_positions)\n",
    "\n",
    "    def update_position_volitive_movement(self, barycenter, step_vol, search_operator):\n",
    "        new_positions = []\n",
    "        for i, pos in enumerate(self.current_position):\n",
    "            new = pos + (((pos - barycenter[i]) * step_vol * np.random.uniform(0, 1)) * search_operator)\n",
    "            if new > 1:\n",
    "                new = 1\n",
    "            elif new < 0:\n",
    "                new = 0\n",
    "            new_positions.append(new)\n",
    "        # volitive_step = [x - y for x, y in zip(self.current_position,barycenter)] / np.linalg.norm([self.current_position, barycenter])\n",
    "        # volitive_step = np.random.uniform(0, 1) * step_vol * volitive_step * search_operator\n",
    "        # new_positions = [x + y for x, y in zip(self.current_position, volitive_step)]\n",
    "\n",
    "        assert len(new_positions) == len(self.current_position)\n",
    "        self.current_position = list(new_positions)\n",
    "\n",
    "\n",
    "\n",
    "class FSS():\n",
    "\n",
    "    def __init__(self, iterations_number, num_of_individuos, probability_of_recombination, dimensions):\n",
    "       \n",
    "        self.dimensions = dimensions\n",
    "        self.iterations_number = iterations_number\n",
    "        self.num_of_individuos = num_of_individuos\n",
    "        self.cluster = []\n",
    "        self.global_best = float(0)\n",
    "        self.global_best_position = []\n",
    "\n",
    "        # Params\n",
    "        self.total_weight = 1 * self.num_of_individuos\n",
    "        self.initial_step_ind = 0.1\n",
    "        self.final_step_ind = 0.0001\n",
    "        self.step_ind = self.initial_step_ind \n",
    "        self.initial_step_vol = 0.01\n",
    "        self.final_step_vol = 0.001\n",
    "        self.step_vol = self.initial_step_vol \n",
    "        self.list_global_best_values = []\n",
    "\n",
    "    def search(self):\n",
    "        self._initialize_cluster()\n",
    "\n",
    "        for i in range(self.iterations_number):\n",
    "            self.evaluate_cluster()\n",
    "            self.updates_optimal_solution()\n",
    "\n",
    "            self.apply_individual_movement()\n",
    "            self.evaluate_cluster()\n",
    "            self.updates_optimal_solution()\n",
    "\n",
    "            self.apply_feeding()\n",
    "\n",
    "            self.apply_instintive_collective_movement()\n",
    "            self.apply_collective_volitive_movement()\n",
    "\n",
    "            self.update_step(i)\n",
    "            self.update_total_weight()\n",
    "\n",
    "            self.evaluate_cluster()\n",
    "            self.updates_optimal_solution()\n",
    "            self.list_global_best_values.append(self.global_best)\n",
    "            if i % 200 == 0:\n",
    "                print(\"iter: {} = cost: {}\".format(i, self.global_best))\n",
    "            \n",
    "            \n",
    "\n",
    "    def update_total_weight(self):\n",
    "        self.total_weight = sum([fish.weight for fish in self.cluster])\n",
    "\n",
    "    def _initialize_cluster(self):\n",
    "        self.cluster = []\n",
    "        for _ in range(self.num_of_individuos):\n",
    "            fish = Fish(\n",
    "                positions=[self._get_random_number() for _ in range(self.dimensions)],\n",
    "                iterations_number = self.iterations_number\n",
    "            )\n",
    "            self.cluster.append(fish)\n",
    "\n",
    "    def evaluate_cluster(self):\n",
    "        for fish in self.cluster:\n",
    "            fish.evaluate()\n",
    "\n",
    "    def updates_optimal_solution(self):\n",
    "        for fish in self.cluster:\n",
    "            if fish.fitness > self.global_best:\n",
    "                self.global_best = fish.fitness\n",
    "                self.global_best_position = list(fish.current_position)\n",
    "\n",
    "    def apply_individual_movement(self):\n",
    "        for fish in self.cluster:\n",
    "            fish.update_position_individual_movement(self.step_ind)\n",
    "\n",
    "    def apply_feeding(self):\n",
    "        max_delta_fitness = max([fish.delta_fitness for fish in self.cluster])\n",
    "        for fish in self.cluster:\n",
    "            fish.feed(max_delta_fitness)\n",
    "\n",
    "    def apply_instintive_collective_movement(self):\n",
    "        sum_delta_fitness = sum([fish.delta_fitness for fish in self.cluster])\n",
    "\n",
    "        for fish in self.cluster:\n",
    "            fish.update_position_collective_movement(sum_delta_fitness)\n",
    "\n",
    "    def _calculate_barycenter(self):\n",
    "        sum_weights = sum([fish.weight for fish in self.cluster])\n",
    "        sum_position_and_weights = [[x * fish.weight for x in fish.current_position] for fish in self.cluster]\n",
    "        sum_position_and_weights = np.sum(sum_position_and_weights, 0)\n",
    "        return [s / sum_weights for s in sum_position_and_weights]\n",
    "\n",
    "    def apply_collective_volitive_movement(self):\n",
    "        barycenter = self._calculate_barycenter()\n",
    "        current_total_weight = sum([fish.weight for fish in self.cluster])\n",
    "        search_operator = -1 if current_total_weight > self.total_weight else 1\n",
    "        for fish in self.cluster:\n",
    "            fish.update_position_volitive_movement(barycenter, self.step_vol, search_operator)\n",
    "\n",
    "    def update_step(self, current_i):\n",
    "        self.step_ind = self.initial_step_ind - current_i * float(\n",
    "            self.initial_step_ind - self.final_step_ind) / self.iterations_number\n",
    "        self.step_vol = self.initial_step_vol - current_i * float(\n",
    "            self.initial_step_vol - self.final_step_vol) / self.iterations_number\n",
    "\n",
    "    def _get_random_number(self):\n",
    "        return np.random.uniform(0, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d73e219-6551-4f48-910f-60f2002566d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
